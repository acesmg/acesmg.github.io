<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[]]></title>
  <link href="http://21stacks.top/atom.xml" rel="self"/>
  <link href="http://21stacks.top/"/>
  <updated>2016-04-19T14:50:06+08:00</updated>
  <id>http://21stacks.top/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[朴素贝叶斯模型]]></title>
    <link href="http://21stacks.top/14609672251727.html"/>
    <updated>2016-04-18T16:13:45+08:00</updated>
    <id>http://21stacks.top/14609672251727.html</id>
    <content type="html"><![CDATA[
<p>　　朴素贝叶斯是一种生成模型，基于贝叶斯定律和特征条件独立性假设，通过先验概率求后验概率。</p>

<h3 id="toc_0">贝叶斯定律</h3>

<p>　　在事件\(A\)发生的情况下，事件\(B\)发生的概率为<br/>
\[P(B|A)=\frac{P(A,B)}{P(A)}\qquad(1)\]<br/>
　　并且有\(P(A,B)=P(AB)=P(B|A)P(A)=P(A|B)P(B)\)。<br/>
　　设有事件群\({B_1,B_2,...}\)，它们两两互斥，且\(B_1+B_2+···=\Omega\)为必然事件，则对任意事件\(A\)有\(P(A)=\sum_{j}P(A,B_j)\)，代入式(1)，得全概率公式<br/>
\[P(A)=\sum_{j}P(B_j)P(A|B_j)\qquad(2)\]<br/>
进而可以得到贝叶斯定律，当事件\(A\)发生时，事件\(B_k\)发生的概率为<br/>
\[P(B_k|A)=\frac{P(A|B_k)P(B_k)}{\sum_{j}P(B_j)P(A|B_j)}\qquad(3)\]</p>

<span id="more"></span><!-- more -->

<h3 id="toc_1">朴素贝叶斯模型的学习</h3>

<p>　　作为一种生成模型，朴素贝叶斯模型对给定输入\(X\)，求条件概率分布\(P(Y|X)\)。设输入空间为\(\chi\subseteq R^n\)，输出空间为集合\(\psi=\{c_1,c_2,...c_K\}\)，训练样本集合为\(T={(x_1,y_1),(x_2,y_2),...(x_N,y_N),}\)。贝叶斯模型首先要求的是先验概率分布<br/>
\[P(Y=c_k),\qquad k=1,2,...,K\]<br/>
以及条件概率分布<br/>
\[P(X=x|Y=c_k),\qquad k=1,2,...,K\]<br/>
然后由贝叶斯公式可得<br/>
\[P(Y=c_k|X=x)=\frac{P(X=x|Y=c_k)P(Y=c_k)}{\sum_{k}P(X=x|Y=c_k)P(Y=c_k)}\qquad (4)\]<br/>
在分类时，若输入为\(X=x\)时，朴素贝叶斯的输出是最大化后验概率的类标签<br/>
\[y=arg\max_{c_k}\frac{P(X=x|Y=c_k)P(Y=c_k)}{\sum_{k}P(X=x|Y=c_k)P(Y=c_k)}\qquad(5)\]<br/>
上式的分母对于不同的类标签\(c_k\)是一样的，因此输出等价于<br/>
\[y=arg\max_{c_k}P(X=x|Y=c_k)P(Y=c_k)\qquad(6)\]<br/>
　　注意到\(P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},X^{(2)}=x^{(2)},...,X^{(n)}=x^{(n)}|Y=c_k)\)。对于离散的多项分布数据样本，假设\(x^{(j)}\)有\(S_j\)种可能的值，那么要求\(P(X=x|Y=c_k)\)，就要求\(K\prod_{j=1}^{n}S_j\)个参数，what a disaster. <strong>朴素</strong>贝叶斯的朴素(Naive)就在于对特征的条件概率作了独立性假设，即假设对于给定的\(X\)，特征各维度之间是独立的。于是由概率的乘法定律有<br/>
\[P(X=x|Y=c_k)=\prod_{j=1}^{n}P(X=x^{(j)}|Y=c_k)\qquad(7)\]<br/>
代入(6)得<br/>
\[y=arg\max_{c_k}P(Y=c_k)\prod_{j=1}^{n}P(X=x^{(j)}|Y=c_k)\qquad(8)\]</p>

<h3 id="toc_2">参数估计</h3>

<p>　　对于朴素贝叶斯模型而已，模型的参数就是前面提到的先验概率和条件概率。朴素贝叶斯模型的学习就是通过训练数据集对这些参数的估计。<br/>
首先是先验概率\(P(Y=c_k)\)。可以直接假设各类别等概率出现，即令\(P(Y=c_k)=\frac{1}{K}\)。也可以从训练样本中各类样本占比得出一个经验估计<br/>
\[P(Y=c_k)=\frac{\sum_{i=1}^{N}I(y_i=c_k)}{N}\qquad(9)\]<br/>
求条件概率\(P(X^{(j)}|Y=c_k)\)的方法因特征类型不同而不同。</p>

<h4 id="toc_3">高斯分布</h4>

<p>　　对于特征值连续的数据集，可以假设各特征符合单变量的高斯分布，因此得到<br/>
\[P(X^{(i)}=x^{(i)}|Y=c_k)=\frac{1}{\sqrt{2\pi\sigma_{c_k}^2}}exp(-\frac{(x^{(i)}-\mu_{c_k})^2}{2\sigma_{c_k}^2})\qquad(10)\]</p>

<h4 id="toc_4">多项分布</h4>

<p>　　对于特征值是离散的，多项分布的情况，假设\(x^{(j)}\)有\(S_j\)种可能的取值\(\{v_{j1},v_{j2},...,v_{jm},...,v_{jS_j}\}\)，则<br/>
\[P(X^{(j)}=v_{jm}|Y=c_k)=\frac{\sum_{i=1}^{N}I(x_i^{(j)}=v_{jm},y_i=c_k)}{\sum_{i=1}^{N}I(y_i=c_k)}\qquad(11)\]<br/>
式(11)在训练集上采用极大似然估计求条件概率。可能某些类标签和特征值的组合并不存在，则对应的条件概率为零，这会抵消其他特征的条件概率，影响模型的准确性。可以加入平滑来解决这一问题，具体的，上式改为<br/>
\[P(X^{(j)}=v_{jm}|Y=c_k)=\frac{\sum_{i=1}^{N}I(x_i^{(j)}=v_{jm},y_i=c_k)+\alpha}{\sum_{i=1}^{N}I(y_i=c_k)+S_j\alpha}\qquad(12)\]<br/>
其中\(\alpha\ge0\)。当取\(\alpha=1\)时，就是拉普拉斯平滑，当\(\alpha&lt;1\)时是Lidstone平滑。相应的，式(9)也加入平滑，得<br/>
\[P(Y=c_k)=\frac{\sum_{i=1}^{N}I(y_i=c_k)+\alpha}{N+K\alpha}\qquad(13)\]</p>

<h4 id="toc_5">二项分布</h4>

<p>　　如果数据集的特征值是符合二项(0-1)分布的，则条件概率\(P(X^{(j)}|Y=c_k)\)可表示为<br/>
\[P(X^{(j)}|Y=c_k)=P(x^{(j)}|c_k)x^{(j)}+(1-P(x^{(j)}|c_k)(1-x^{(j)}))(14)\]</p>

<h3 id="toc_6">Reference</h3>

<blockquote>
<p>[1] 李航，统计学习方法<br/>
[2] Scikit-Learn, <a href="http://scikit-learn.org/stable/modules/naive_bayes.html">Naive Bayes</a></p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[粒子群优化算法]]></title>
    <link href="http://21stacks.top/14605499748686.html"/>
    <updated>2016-04-13T20:19:34+08:00</updated>
    <id>http://21stacks.top/14605499748686.html</id>
    <content type="html"><![CDATA[
<p>　　粒子群优化算法(Partlcle Swarm Optimization, PSO)是一种基于群体智能的搜索算法。 PSO具有参数配置简单、搜索性能好、可适应性强等优势，因而得到了广泛的应用。本文将从优化问题的基本概念说起，介绍基本PSO算法原理以及它的一些变体。</p>

<h2 id="toc_0">Motivation</h2>

<h3 id="toc_1">什么是优化问题</h3>

<p>　　优化，就是要在多种方案中寻找最好的方案。比如有的妹子们出门见男盆友之前恨不得把所有衣服都试一遍，以找到一种最满意的搭配。不过一般情况下她们可能看哪件衣服都觉得不完美，然后要么选择一件还算顺眼的凑活一下，要么愉快地开始了网购...就像妹子们选衣服那样，典型的优化问题通常是不太可能在可接受的时间之内找到一个全局最优解(Global Optimum)的，所以只能想办法在合理的时间内找到一个可接受的解(Local Optimum)。旅行商问题(TSP)、神经网络的训练、无线传感器网络(WSN)的任务调度等，都是常见的优化问题。</p>

<span id="more"></span><!-- more -->

<h3 id="toc_2">优化算法</h3>

<p>　　先明确几个概念。<br/>
　　什么是<strong>可行解</strong>？回到妹子挑衣服的问题，只要还能穿的衣服，不管好不好看挨不挨冻，都算是可行解。<br/>
　　什么是<strong>解空间</strong>？所有可行解所构成的集合就是解空间，这个“空间”是抽象的，可能很多维，甚至可能是离散而非连续的。优化算法要做的，就是在解空间中的各个可行解中，尽可能地找到更好的解。这是一个搜索过程，所以优化算法也叫搜索算法(不是Searching Engine那种搜索)。<br/>
　　什么是<strong>目标函数</strong>？不同的优化算法有着不同的搜索策略，因此可能在不同的问题上表现出各自的优越性。另外需要明确，怎样的解算是一个好的解？我们必须确定一个标准来评价解的好坏。这通常要根据问题本身的特性来建立一个目标函数(Objective Function)。相比于试衣服时的标准(好看)而言，我们的目标函数是要有明确的数学定义的。因此或许对于前面这个例子，可以改用回头率、男朋友的心跳频率等可量化的标准来作为目标函数。于是优化算法要做的就是对目标函数的解空间寻优。在训练神经网络时，以损失函数(Cost Function)\(J(W,b)\)为目标函数，优化目标就是要极小化损失函数的值。<br/>
　　典型的优化算法有经典的模拟退火、梯度下降等。还有遗传算法、蚁群算法、粒子群优化算法等群智能算法，它们基于对生物群体行为的认知、抽象、借鉴。啊...神奇的大自然...</p>

<h2 id="toc_3">粒子群优化算法简介</h2>

<h3 id="toc_4">起源</h3>

<p>　　粒子群算法源于对鸟群行为的研究。群居的鸟类通常要倾巢出动去寻找食物。对于在鸟群中的一只小小鸟(它名叫Birdy)来说，它处在空间中的某个位置(可以用经度，维度，海拔来定位)；它在飞行着，因此有速度(包括速率大小和方向)；它当前的速度和位置，决定了它下一时刻会处在什么位置。Birdy是一只有主见的鸟，它有着自己的当前飞行速度；它很聪明，能记住自己曾经到过的位置中哪些可能有丰富的食物；而且它是跟着三姑四婆七舅姥爷一起出门的，它也知道大家各自找到的位置中哪个是食物最丰富的。Birdy的飞行就依靠着三个信息的指引，最终它和亲戚们合力找到了一个可以满足它们食物需求的地方。对以上的描述做一个抽象。在解空间中随机放置一定数量的粒子，每一个粒子所在的位置就是它所代表的解；同时粒子是在运动的，它有速度，会在解空间中移动。每个粒子的移动过程就是根据当前速度和位置去往下一刻的位置。粒子们作为一个群体是相互协同和制约的。每一个粒子要根据三个因素来确定它下一刻的速度：自己当前的速度，这代表了它本身的搜索能力；自己目前为止找到的最好位置，这是它的认知部分；目前为止整个群体所能找到的最好位置，这是社会部分。 </p>

<h3 id="toc_5">细节</h3>

<p>　　粒子群优化(PSO)中单个粒子速度和位置的更新可以用下面两式表达：<br/>
\[V^{(i+1)}=\omega V^{(i)}+c_1r_1(pbest-X^{(i)})+c_2r_2(gbest-X^{(i)})\qquad(1)\\<br/>
X^{(i+1)}=X^{(i)}+V^{(i+1)}\qquad(2)\]<br/>
　　其中\(V\)是粒子的速度，\(X\)则是粒子的位置，它们都是多维的向量或矩阵；\(i\)表示迭代次数。公式(1)右边的多项式中的三项分别是粒子当前速度，代表粒子本身的搜索能力；粒子当前位置与粒子自身的历史最佳位置(\(pbest\))的差距，代表其自我认知；当前位置与整个群体的历史最佳位置(\(gbest\))的差距，代表粒子的社会性。粒子下一刻的速度是这个三个者的和。\(\omega\)、\(c_1\)和\(c_2\)是预先设置的参数，改变它们的大小可以调整这三项的影响力(权重)。\(r_1\)和\(r_2\)是两个\((0,1)\)之间的随机数，每次更新速度都要重新生成。粒子的位置更新由公式(2)表示，这一步只需给当前位置加上一个更新后的速度。粒子群算法的执行过程要经历多次迭代，每一次迭代的过程就是更新粒子速度和位置的过程、获取新的适应函数值；并且如果产生了更好的位置，还要更新\(pbest\)和\(gbest\)。所谓更好的位置，如果目标是极小化适应值函数，则在适应值函数上有更小值的位置是更好的位置。下面两图分别表示二维平面上粒子的速度和位置更新过程。<br/>
<img src="http://7xrz9i.com1.z0.glb.clouddn.com/psoPSO%E9%80%9F%E5%BA%A6%E6%9B%B4%E6%96%B0.jpg?imageView/2/w/500" alt=""/><br/>
<img src="http://7xrz9i.com1.z0.glb.clouddn.com/psoPSO%E4%BD%8D%E7%BD%AE%E6%9B%B4%E6%96%B0.jpg?imageView/2/w/500" alt="&quot;图1&quot;"/><br/>
　　\(c_1\)、\(c_2\)通常都设置为2.0。\(\omega\) 的值设为\((0,1)\)之间的一个实数，它可以是确定的，也可以随着迭代次数增加而不断减小。随着迭代的进行，个体位置\(X\)与\(pbest\)和\(gbest\)的差距会越来越小。也就是说，后两项对速度的影响会越来越小。而且速度在每一次迭代都会被乘以一个小于1的\(\omega\) ，因此速度会趋于零。当速度不断趋于零的时候，粒子的位置变动也越来越慢，直至停滞不动。这就是粒子群的收敛过程。<br/>
下面的伪代码概括了PSO的执行过程。</p>

<p><strong>输入</strong>：适应值函数\(F(X)\)；种群规模 SwarmSize；最大迭代次数 MaxIter；\(c_1\)、\(c_2\)、\(\omega\)。<br/>
<strong>输出</strong>：\(X=arg\min_{X}F(X)\)。</p>

<pre><code>初始化: 生成SwarmSize个粒子，随机初始化它们的位置和速度。 
Get fitness for each particle
Get gbest
Set pbest as the current position for each particle
for IterNum = 1, 2,...,MaxIter
    for each particle
        renew V
        renew X
        renew Fitness
        renew pbest
    renew gbest
return gbest
</code></pre>

<p>　　对于PSO这类基于群体智能的搜索算法，应该尽量保证个体间的多样性。所谓多样性，就是说个体之间存在着差异，就像生物多样性那样。公式(1)中的随机数\(r_1\)和\(r_2\)就是一种提高多样性的机制。个体的多样性越好，它们在解空间中的分布就越广，群体的搜索能力就越强，陷入局部最优解的可能性就越小。这里存在着一对矛盾：一方面我们希望尽可能地保持粒子的多样性，以提高群体都搜索能力；另一方面我们希望粒子的运动是趋于收敛的，也就是希望粒子的位置会在合理的时间内逐渐趋同。很多对于PSO算法的改进就是着眼于对这对矛盾之间的均衡。</p>

<h2 id="toc_6">改进</h2>

<p>　　对PSO的改进大多围绕提高粒子多样性和保证收敛速度来进行。这里主要介绍三种：引入变异、邻域PSO、综合学习(Comprehensive Learning)。</p>

<h3 id="toc_7">引入变异</h3>

<p>　　变异的概念来源于生物进化(依旧是神奇的大自然)。在物种进化的过程中主要起作用的因素有：自然选择，适者生存，优胜劣汰；个体之间的基因交流，重组出新的基因；个体自身的变异产生新的基因。变异发生的概率很低，但对于物种多样性有着非常重要的意义。对于生物进化的认知、抽象、运用，得出了著名的遗传算法(Genetic Algorithm, GA)。我们可以从GA中借鉴变异操作，来提高PSO中群体的多样性。我们预先设定一个较小的变异率参数muRate(比如0.02)，在每次迭代中随机产生一个数，如果这个数小于muRate，则进行变异操作。具体的变异操作可以是对位置X增减一个随机值，可以随机重置某些维度，甚至可以重新随机初始化整个粒子。变异操作为陷入局部最优解的群体提供了跳变的可能，从而可以提高群体的搜索能力。</p>

<h3 id="toc_8">邻域PSO</h3>

<p>　　实验表明，公式(1)中的最后一项，即历史最优解，对于整个群体的影响力非常大。它很有可能把群体带向一个并不是很好的位置，使得群体陷于局部最优解。可以通过减缓历史最优解信息的传递速度，来保持粒子多样性。由这个思想产生了各种基于邻域的PSO算法。它们的共同特点是，把最后一项的群体历史最优改成个体邻域内的历史最优解:<br/>
\[V^{(i+1)}=\omega V^{(i)}+c_1r_1(pbest-X^{(i)})+c_2r_2(lbest-X^{(i)})\qquad(3)\]<br/>
对于一个粒子来说，\(lbest\)就是它处在的邻域范围内的各个粒子目前为止所得到的最优解。常见的邻域有环形邻域、随机邻域、von Neumann邻域等。</p>

<h3 id="toc_9">综合学习</h3>

<p>　　综合学习策略(Comprehensive Learning，CL)同样认为在基本PSO算法中，gbest的影响力过于强大，容易很快把群体带到一个局部最优解位置，因此应该想办法限制gbest的影响。怎么限制？直接把它去掉。于是就得到了一个右边只有两项的速度更新公式:<br/>
\[V^{(i+1)}=\omega V^{(i)}+cr(pbest_f-X^{(i)})\qquad(4)\]<br/>
这里的\(pbest\)也不再是原来的\(pbest\)，它是一个组合体，虽然形态和普通的\(pbest\)还是一样的，但它的不同维度可能来自不同的粒子。通过把较好的粒子的某些维度重组在一起，得到了新的\(pbest_f\)。它掌握着来自整个群体的好的信息，因此有能力指引着群体去往更好的位置。而当种群中个体越来越接近，它们的速度也逐渐趋于零，于是慢慢地收敛了。关于CL的更多细节请参考附录[1]。<br/>
　　以上的改进都会在一定程度上使群体的收敛速度变慢，因此需要更多的迭代次数。对于解空间不复杂的问题，综合学习的优势并不突出。而当被用来解决各种复杂多峰的优化问题时，它在寻优能力方面的优势就很明显了。</p>

<h2 id="toc_10">组合优化</h2>

<p>　　以上描述的都是对于连续问题的优化算法。针对离散问题，PSO也有对应的版本。对于离散PSO(BPSO)，粒子的位置是离散的值。基本BPSO的粒子的编码为0-1编码，即粒子中的每一维度非0即1。而速度的各个维度依然是连续的，因此我们需要一个函数，将连续的速度值映射成离散的位置值。最常用的映射函数是\(sigmoid\)函数，原始的BPSO使用以下两个公式更新粒子的位置：<br/>
\[S({V_j}^{(i)})=\frac{1}{1+e^{-{V_j}^{(i)}}}\qquad(5)\]<br/>
\[{X_j}^{(i+1)}=\begin{cases}<br/>
0 &amp; \text{ if } random\geqslant S({V_j}^{(i)}) \\<br/>
1 &amp; \text{ if } random&lt; S({V_j}^{(i)})<br/>
\end{cases}\qquad(6)\]  </p>

<p>这里\(V^{(i)}_{j}\)表示在第\(i\)次迭代时粒子速度的第\(j\)维。\(sigmoid\)函数的形态如下图所示：<br/>
<img src="http://7xrz9i.com1.z0.glb.clouddn.com/psoSigmoid.png" alt=""/><br/>
观察其函数形态可以发现，当速度趋于0的时候，其函数值趋于0.5。这也就是说，对应维度的位置值是0还是1，是等可能的。这并不符合我们所预期的目标：当速度趋于收敛的时候位置也趋于不变。<br/>
　　一个更合理的方案是采用一种在输入为0时其函数值也为0的函数，例如\(T(X)=\left | tanh(X) \right |\)。这类函数的形态像一个V形：<br/>
<img src="http://7xrz9i.com1.z0.glb.clouddn.com/psoVshaped.png" alt=""/><br/>
如果采用V形函数，则位置更新方式也要跟着改为下式，使得当速度趋于0时，位置趋于不变：<br/>
\[{X_j}^{i+1}=\begin{cases}<br/>
0 &amp; \text{ if } random\leqslant T({V_j}^{i}) and {V_j}^{i}\leqslant 0\\\ <br/>
1 &amp; \text{ if } random\leqslant T({V_j}^{i}) and {V_j}^{i}&gt; 0 \\\ <br/>
{X_j}^{i} &amp; \text{ if } random&gt; T({V_j}^{i}) <br/>
\end{cases}\]<br/>
　　这里还要重点安利一种神奇的离散PSO框架，基于集合的离散PSO(Set-based PSO，SPSO)。SPSO的框架非常灵活，可以很好地整合其他算法思想，比如结合综合学习策略；且其编码方式可以自如地根据实际问题来设计。详见参考文献[2]。<br/>
　　</p>

<h2 id="toc_11">Reference</h2>

<blockquote>
<p><a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1637688&amp;newsearch=true&amp;queryText=comprehensive%20learning%20particle%20swarm">1. Comprehensive Learing PSO</a><br/>
<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5299261&amp;newsearch=true&amp;queryText=set-based%20particle%20swarm">2. Set-based PSO</a></p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SSE的背后]]></title>
    <link href="http://21stacks.top/14600116978074.html"/>
    <updated>2016-04-07T14:48:17+08:00</updated>
    <id>http://21stacks.top/14600116978074.html</id>
    <content type="html"><![CDATA[
<h3 id="toc_0">定义</h3>

<p>　　Sum of Square Error (SSE)代价函数用于衡量一个模型对数据的拟合程度。其形式化的表述为<br/>
\[C(\theta)=\frac{1}{2}\sum_{i=1}^{N}(y_i-h_{\theta}(x_i))^2\qquad(1)\]</p>

<span id="more"></span><!-- more -->

<p>　　其中\((x_i, y_i)\)是数据样本，\(x_i\in R^n\)；\(h_{\theta}(x)\)是以\(\theta\)为参数的模型，假设(hypothesis)。在前面加一个系数\(\frac{1}{2}\)的为了方便处理某些运算。注意还有一个常见的概念，平均平方误差(Mean Square Error, MSE)，它是SSE在数据集上的均值，是以平方损失函数为基础的经验风险函数。MSE是一种与数据集大小无关的误差衡量，本质上跟SSE并没有什么软区别。<br/>
\[MSE=\frac{1}{2N}\sum_{i=1}^{N}(y_i-h_{\theta}(x_i))^2\qquad(2)\]</p>

<h3 id="toc_1">直观含义</h3>

<p>　　从式(1)可以清楚地看到，SSE直观地表示了模型\(h_{\theta}(x)\)对\(y\)的拟合程度的好坏。\(SSE\geq 0\)，且拟合程度越好SSE越小，一个完美拟合的模型会使SSE为0。在对数据集建立分类或回归模型时，我们追求的目标是尽可能地找到一个模型，使得<br/>
\[y=h_{\theta}(x)\qquad(3)\]<br/>
　　很多算法对模型的学习策略都是通过极小化SSE来实现的。不幸的是，我们总不能完美找到一个这样的模型。不能的意思有两层。一是说能力不够，受制于所选模型特性等因素，并不总能得到一个完美的拟合，例如无法用感知机模型对线性不可分的数据完美地划分。 二是说不应该，在训练数据集上完美拟合的模型通常是过拟合的泛化能力不好的模型。后者的主要原因是训练数据中存在的噪声，以及模型自身的缺陷。因此通常情况下，由模型得出的预测值与\(y\)之间的关系是这样的<br/>
\[y=h_{\theta}(x)+\epsilon\qquad(4)\]<br/>
　　\(\epsilon\)表示\(\hat{y}=h_{\theta}(x)\)对\(y\)的误差。在回归分析中称\(\epsilon=y-h_{\theta}(x)\)为残差，而式(1)也被称为残差平方和(Residual Sum of Square, RSS)。可以采用最小二乘法来求解极小化RSS问题。若模型是参数\(\theta\)的线性函数，可以求得封闭解；否则可以采用迭代方式求解。</p>

<h3 id="toc_2">从参数估计的角度来看</h3>

<p>　　为什么通过极小化SSE得到的模型是好的？除了直观感觉，我们也可以从参数估计的角度做一些推理。这里我们关注的是式(4)中的误差<br/>
\[\epsilon=y-h_{\theta}(x)\qquad(5)\]<br/>
　　对于一组数据\(\{(x_1,y_1),(x_2,y_2),...,(x_i,y_i),...,(x_N,y_N)\}\)，可以得到一组误差值\(\{\epsilon_1,\epsilon_2,...,\epsilon_i,...,\epsilon_N \}\)。通常认为这个误差集里的数据是源于总体分布\(f(x;\theta)\)的抽样，它们独立同分布。因此所有\(\epsilon\)的联合概率密度为<br/>
\[f(\epsilon_1,...,\epsilon_N;\theta)=f(\epsilon_1;\theta)f(\epsilon_2;\theta)\cdot\cdot\cdot f(\epsilon_N;\theta)\qquad(6)\]<br/>
　　记\(L(\epsilon_1,...,\epsilon_N;\theta)=f(\epsilon_1,...,\epsilon_N;\theta)\)为似然函数，\(\theta\)是待估计的参数。若\(L(\epsilon_1,...,\epsilon_N;\theta_1)&gt;L(\epsilon_1,...,\epsilon_N;\theta_2)\)，我们说当已知\(\{\epsilon_1,...,\epsilon_N\}\)时，待估计参数\(\theta\)是\(\theta_1\)的可能性大于\(\theta_2\)。因此我们有了一个优化目标：要寻求一个\(\theta&#39;\)，使\(L\)尽可能大。<br/>
　　进一步假设\(\epsilon_i\)是均值为0的高斯噪声(Or, what else can it be ?)；其方差为某\(\sigma^2\)。即\(\epsilon\)的分布的概率密度函数为<br/>
\[f(\epsilon|\theta)=(\frac{1}{2\pi\sigma^2})^{\frac{1}{2}}exp(-\frac{\epsilon^2}{2\sigma^2})\qquad(7)\]<br/>
于是，似然函数可写成<br/>
\[L(\theta)=\prod_{i=1}^{N}(\frac{1}{2\pi\sigma^2})^{\frac{1}{2}}exp(-\frac{\epsilon_i^2}{2\sigma^2})\qquad(8)\]<br/>
为了方便处理，对式(8)左右两边去自然对数，\(g(z)=lnz\)是\(z\)的单调递增函数，因此优化目标不变。整理得<br/>
\[lnL(\theta)=-\frac{1}{2\sigma^2}\sum_{i=1}^{N}\epsilon^2-\frac{N}{2}ln(2\pi\sigma^2)\qquad(9)\]<br/>
将式(5)代入(9)，得<br/>
\[lnL(\theta)=-\frac{1}{2\sigma^2}\sum_{i=1}^{N}(y_i-h_{\theta(x_i)})^2-\frac{N}{2}ln(2\pi\sigma^2)\qquad(10)\]<br/>
式(10)中，等号右边的第二项与\(\theta\)无关，因此要极大化\(lnL(\theta)\)就是要极大化等号右边第一项。由于\(\sigma^2\)是某个正实数，因此我们的优化目标就相当于求<br/>
\[\theta&#39;=arg\min_{\theta}\frac{1}{2}\sum_{i=1}^{N}(y_i-h_{\theta}(x_i))^2\qquad(11)\]<br/>
式(11)正是极小化SSE的方法所寻求的，也就是说，极小化SSE等价于极大似然估计。前文假设\(\epsilon\)服从高斯分布。高斯分布属于指数族分布。参考文献[4]指出，当观测样本来源于指数族分布，辅以适当条件，最小二乘法就等价于极大似然估计。<br/>
　　对于线性回归模型，\(h_{\theta}(x)=\theta^Tx\)，代入(11)得<br/>
\[\theta&#39;=arg\min_{\theta}\frac{1}{2}\sum_{i=1}^{N}(y_i-\theta^Tx_i)^2\qquad(12)\]<br/>
求解(12)式既可以采用求导函数零点求封闭解，也可以使用迭代式的解法如<a href="http://acesmg.github.io/14598347945676.html">梯度下降法</a>。</p>

<h3 id="toc_3">Reference</h3>

<blockquote>
<p>[1] 陈希孺，概率论与数理统计<br/>
[2] Wikipedia: <a href="https://en.wikipedia.org/wiki/Maximum_likelihood">Maximum Likelihood</a><br/>
[3] Murphy, Machine Learning: A Probabilistic Perspective.<br/>
[4] A.Charnes etc, <a href="http://www.tandfonline.com/doi/abs/10.1080/01621459.1976.10481508">The Equivalence of Generalized Least Squares and Maximum Likelihood Estimates in the Exponential Family</a></p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[美好的Python]]></title>
    <link href="http://21stacks.top/14608664015957.html"/>
    <updated>2016-04-17T12:13:21+08:00</updated>
    <id>http://21stacks.top/14608664015957.html</id>
    <content type="html"><![CDATA[
<p>人生苦短，我用Python。本文旨在收集记录分享简洁漂亮的Python写法，欢迎补充。</p>

<h4 id="toc_0">字典/集合推导式(dict/set comprehension)</h4>

<p>类似于列表推导式：</p>

<pre><code class="language-python">my_dict = {i: i * i for i in xrange(100)} 
my_set = {i * 15 for i in xrange(100)}
#这俩在写法上的区别只是字典推导式多了一个&#39;:&#39;
</code></pre>

<p><strong>Caution：</strong><br/>
区别一下三种写法：</p>

<pre><code class="language-python">&gt;&gt;&gt;my_set = {i*15 for i in xrange(100)}
&gt;&gt;&gt;my_list = [i*15 for i in xrange(100)]
&gt;&gt;&gt;my_generator = (i*15 for i in xrange(100))

&gt;&gt;&gt;print &quot;my_set&quot;, type(my_set)
my_set &lt;type &#39;set&#39;&gt;
&gt;&gt;&gt;print &quot;my_list&quot;, type(my_list)
my_list &lt;type &#39;list&#39;&gt;
&gt;&gt;&gt;print &quot;my_generator&quot;, type(my_generator)
my_generator &lt;type &#39;generator&#39;&gt;
</code></pre>

<span id="more"></span><!-- more -->

<h4 id="toc_1">枚举 (enumerate)</h4>

<p>要在枚举过程中使用序号，可以采用<code>enumerate</code>优雅地实现：</p>

<pre><code class="language-python">#i从0开始,每次加1
for i, item in enumerate(iterable):
    print i, item
#i从2开始
for i, item in enumerate(iterable, 2):
    print i, item
</code></pre>

<h3 id="toc_2">强制浮点数除法</h3>

<p>如果我们对两个整数做<code>/</code>除法，Python 2 返回的是一个整数，如需返回浮点数的结果，在Python 2.x中通常会这么做：</p>

<pre><code class="language-python">&gt;&gt;&gt;1.0/2
0.5
</code></pre>

<p>可以这样更漂亮地实现：</p>

<pre><code class="language-python">&gt;&gt;&gt;from __future__ import division 
&gt;&gt;&gt;1/2
0.5
</code></pre>

<p>而在Python 3中，<code>/</code>是真除，默认精确到小数点后一位。</p>

<h4 id="toc_3">使用literal_eval()</h4>

<p>我们都知道eval:</p>

<pre><code class="language-python">expr = &quot;[1, 2, 3]&quot; 
my_list = eval(expr)
</code></pre>

<p>但估计没几个人知道literal_eval( ):</p>

<pre><code class="language-python">import ast 
my_list = ast.literal_eval(expr)
</code></pre>

<p>(看起来好像并没有变漂亮呢，但ast.literal_eval()更安全。)</p>

<h4 id="toc_4">用dir( )查看一个Python对象</h4>

<pre><code class="language-python">&gt;&gt;&gt; foo = [1, 2, 3, 4]
&gt;&gt;&gt; dir(foo) 
[&#39;__add__&#39;, &#39;__class__&#39;, &#39;__contains__&#39;, 
&#39;__delattr__&#39;, &#39;__delitem__&#39;, &#39;__delslice__&#39;, ... , 
&#39;extend&#39;, &#39;index&#39;, &#39;insert&#39;, &#39;pop&#39;, &#39;remove&#39;, 
&#39;reverse&#39;, &#39;sort&#39;]
</code></pre>

<h4 id="toc_5">调试脚本</h4>

<p>利用pdb模块可以轻松地在脚本中设置断点：</p>

<pre><code class="language-python">import pdb
pdb.set_trace()
</code></pre>

<p>你可以在脚本的任何位置加上<code>pdb.set_trace()</code>来设置断点。</p>

<h4 id="toc_6">简化if 结构</h4>

<p>当有多个值需要检验的时候，通常会这么写：</p>

<pre><code class="language-python">if n==1 or n==4 or n==5 or n==6:
</code></pre>

<p>更漂亮的写法是：</p>

<pre><code class="language-python">if n in [1,4,5,6]:
</code></pre>

<h4 id="toc_7">反转列表/字符串</h4>

<p>你可以这样快速地反转一个列表：</p>

<pre><code class="language-python">&gt;&gt;&gt;a=[1,2,3]
&gt;&gt;&gt;a[::-1]
[3,2,1]
</code></pre>

<p>这样会生成一个新的列表，原列表不变。如果你想在原地反转列表，可以这样：</p>

<pre><code class="language-python">&gt;&gt;&gt; a.reverse()
&gt;&gt;&gt; a
[3, 2, 1]
</code></pre>

<p>字符串类型string是不可变类型，因此也就没有对应的reverse( )咯。</p>

<h4 id="toc_8">行内if</h4>

<pre><code class="language-python">a = 1 if b&gt;c else -1
print a if b&gt;c else d
</code></pre>

<h4 id="toc_9">交换两个变量</h4>

<pre><code class="language-python">a, b = b, a
</code></pre>

<h4 id="toc_10">连续赋值</h4>

<pre><code class="language-python">a, b, c = 1, 2, 3
</code></pre>

<h3 id="toc_11">串联</h3>

<pre><code class="language-python">&gt;&gt;&gt;a=[1,2]
&gt;&gt;&gt;b=[3,4]
&gt;&gt;&gt;a+b
[1,2,3,4]
&gt;&gt;&gt;print str(1) + &quot; a&quot;
1 a
&gt;&gt;&gt;print `1` + &quot; b&quot;
1 b
&gt;&gt;&gt;print 1, &quot; c&quot;
1 c
</code></pre>

<h4 id="toc_12">地板除 (Python 2.2以后)</h4>

<pre><code>&gt;&gt;&gt;5//2
2
&gt;&gt;&gt;5.0//2
2.0
</code></pre>

<h4 id="toc_13">乘方</h4>

<pre><code>#a**b, 得a的b次方
&gt;&gt;&gt;2**5
32
</code></pre>

<h4 id="toc_14">级联比较</h4>

<pre><code class="language-python">if a&lt;b&lt;c:
    blabla...
if a&lt;b&gt;c:
    blabla...
</code></pre>

<h4 id="toc_15">同时遍历两个列表：</h4>

<pre><code class="language-python">names=[&#39;Tom&#39;,&#39;Jerry&#39;]
ages=[23,17]
for name, age in zip(names, ages):
    print name, age
</code></pre>

<h4 id="toc_16">建立并初始化列表</h4>

<pre><code class="language-python">#一维
a=[0]*4
#二维, 3行4列
b=[[0]*4 for i in range(3)]
</code></pre>

<h4 id="toc_17">join( )</h4>

<pre><code class="language-python">&gt;&gt;&gt;a=[&#39;my&#39;, &#39;life&#39;, &#39;is&#39;, &#39;awesome&#39;]
&gt;&gt;&gt;print &#39;!&#39;.join(a)
my!life!is!awesome
</code></pre>

<h4 id="toc_18">获取字典内的元素</h4>

<pre><code class="language-python">#bad practice：
dix = {&#39;Tom&#39;:23}
try:
    name = dix[&#39;Tom&#39;]
except KeyError:
    name = &#39;Default&#39;
    
#good practice：
name = dix.get(&#39;Tom&#39;, &#39;Default&#39;)
</code></pre>

<h4 id="toc_19">截取列表的一部分</h4>

<pre><code class="language-python">&gt;&gt;&gt;a = [1,2,3,4,5,6]
&gt;&gt;&gt;a[:3]
[1,2,3]
&gt;&gt;&gt;a[1:5]
[2,3,4,5]
&gt;&gt;&gt;a[-3:]
[4,5,6]
&gt;&gt;&gt;a[::2]
[1,3,5]
&gt;&gt;&gt;a[1::2]
[2,4,6]
</code></pre>

<p>对于a[x:y:z], x和y分别是下标起点和下标终点+1，z是间隔值。于是就能理解为啥a[::-1]能得到一个反转的列表了。</p>

<h4 id="toc_20">向列表添加元素</h4>

<pre><code class="language-python">my_list = [1,2,3]
my_list += 4,
#my_list变成了[1,2,3,4]
my_list += [5]
#my_list变成了[1,2,3,4,5]
</code></pre>

<h4 id="toc_21">不断更新中...</h4>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[整数除法、取余、舍入，Python VS Java]]></title>
    <link href="http://21stacks.top/14608736410354.html"/>
    <updated>2016-04-17T14:14:01+08:00</updated>
    <id>http://21stacks.top/14608736410354.html</id>
    <content type="html"><![CDATA[
<p>　　关于除法，你也许觉得没什么值得谈论的，毕竟小学的时候体育老师就教过我们了。然而对于编程中使用的除法，我觉得还是有很多值得注意的细节的。为什么我想深究一下？因为我日常主要使用Java和Python编程，而它们的除法在细节上有很多不同之处，全是坑啊…所以接下来我也将着重于Java和Python，但是相信我，就算你不用Java和Python，也会有所收获的。</p>

<h3 id="toc_0">1.整数除法</h3>

<p>　　对两个不能整除的整数做除法，就要面对舍入的问题。和大多数编程语言一样，Java的基本舍入策略是向零取整(round to zero)，也就是向绝对值变小的方向取整。举几个香甜的小栗子：3/2=1, -3/2=-1。而对于Python而言，情况就有所不同了，例如：</p>

<pre><code class="language-python">&gt;&gt;&gt;-1/10
-1
</code></pre>

<p>　　显然如果按照Java的取整策略，-1/10应该得0，而Python给出的结果是-1。事实上Python的取整方式是向下取整，也就是向着数轴上负无穷的方向取整。<br/>
　　好吧，Java和Python的取整方式不同，那又怎样，夺大点事儿呀…<br/>
　　那么如果我们要在Python下得到向零取整的结果，咋整？一种比较直接的方式是：</p>

<pre><code class="language-python">&gt;&gt;&gt;int(float(-1)/10)
0
</code></pre>

<span id="more"></span><!-- more -->

<h3 id="toc_1">2.取余</h3>

<p>　　Java和Python整数除法都遵循下面这个公式：<br/>
\[(\frac{a}{b})*b+c=a\]<br/>
　　也就是说：<br/>
\[a \% b=c=a-(\frac{a}{b})*b\]<br/>
　　这里用\(\frac{a}{b}\)表示整数除法。既然它们的取整方式不一样，那么取余也会受到影响。对Java，\(-2\%3=-2\)；而对于Python，\(-2\%3=1\)。<br/>
在某些实际应用中，我们可能需要获得一个整数的各位的数字。如果输入的整数的正的，Java和Python都可以用相同的方法来解决： </p>

<pre><code class="language-python">#Python
def func(a):
    pos, res=1, []
    while a/pos:
        res += (a/pos)%10,
        pos *= 10
    return res
</code></pre>

<p>　　Java代码也差不多就是这样了。但如果输入的整数是一个负数，Java版本的代码还是可以得到正确的结果，而Python不能。那怎样用Python正确地搞定这个问题嘞？可以先取绝对值和符号，当作正数来处理，最后再在结果里搭上符号。 </p>

<h3 id="toc_2">3. Follow-ups</h3>

<h4 id="toc_3">3.1 Python中的另一个除法操作</h4>

<p>　　我们知道，在Python中，基本的除号<code>/</code>是被重载了的。当两个操作数都是整数时，进行整数除法，得到整数结果，否则进行浮点数除法（真除法），得到浮点数结果。从Python 2.2开始，另一个除号被引入：<code>//</code>，它只执行整数除法。注意，<code>//</code>的结果类型依操作数而定。</p>

<pre><code class="language-python">&gt;&gt;&gt;1.0/2
0.0
&gt;&gt;&gt;1.0//2.0
0.0
&gt;&gt;&gt;1//2
&gt;0
</code></pre>

<p>另外，如果想同时得到商和余数，可以使用内建的函数divmod，结果是一个tuple。</p>

<pre><code class="language-python">&gt;&gt;&gt;divmod(7, 2)
(3, 1)
&gt;&gt;&gt;divmod(7.0, 2)
(3.0, 1.0)
</code></pre>

<h4 id="toc_4">3.2 Python中的舍入</h4>

<p>　　除了缺省的舍入方式，Python还有多种舍入可供选择。<br/>
<strong>Floor rounding:</strong></p>

<pre><code class="language-python">&gt;&gt;&gt;import math
&gt;&gt;&gt;math.floor(1.2)
1.0
&gt;&gt;&gt;math.floor(-1.2)
-2.0
</code></pre>

<p><strong>Ceiling rounding:</strong></p>

<pre><code class="language-python">&gt;&gt;&gt;math.ceil(1.2)
2.0
&gt;&gt;&gt;math.ceil(-1.2)
-1.0
</code></pre>

<p><strong>Round-off:</strong></p>

<pre><code class="language-python">&gt;&gt;&gt;round(0.5)
1.0
&gt;&gt;&gt;round(-0.4)
-0.0
&gt;&gt;&gt;round(-0.5)
-1.0
</code></pre>

<p>内嵌的<code>round</code>函数也可以指定一个保留小数位数的参数：</p>

<pre><code class="language-python">&gt;&gt;&gt;round(0.21, 1)
0.2
&gt;&gt;&gt;round(0.21, 2)
0.21
</code></pre>

<p><strong>Caution !</strong></p>

<pre><code class="language-python">&gt;&gt;&gt;round(2.675, 2)
2.67
</code></pre>

<p>咦？bug啦？！当然不是。这里要明确一件事：计算机只认识0,1。就是说，我们输入的十进制数，在计算机内部都是用二进制来表示的。有的十进制数可以用二进制准确地表示，比如十进制的0.125可以表示为0b0.001；然而很多的小数是没法用二进制数精确表示的，计算机里存储的是它们的近似值，例如十进制的0.1，用二进制表示，可以近似为: <code>0b0.00011001100110011001100110011001100110011001100110011010</code>，所以当我们把它换回十进制数以输出或者使用，得到的值就是<code>0.1000000000000000055511151231257827021181583404541015625</code>。也就是说，0.1在计算机里并不是刚好等于1/10的。</p>

<pre><code class="language-python">&gt;&gt;&gt;0.1 + 0.2
0.30000000000000004
</code></pre>

<p>同样，当我们运行<strong>round( )</strong>函数，也是对计算机中实际存储的值近似取舍。2.67实际上近似为<code>2.67499999999999982236431605997495353221893310546875</code>，你看第三位小数是4，那么<code>round(2.675, 2)</code>就相当于<code>round(2.674, 2)</code>，结果当然是2.67。值得注意的是，这种现象是广泛存在于各种计算机和各种编程语言的，不是bug。</p>

<h4 id="toc_5">3.3 Java中的舍入</h4>

<p>　　Java提供了floor和ceil方法来实现向下和向上取整。</p>

<pre><code class="language-java">Math.floor(2.9)
Math.ceil(2.1)
</code></pre>

<p>　　这俩函数简单方便，居家旅行必备。另外Java中也有个round函数，可以实现各种复杂的取整。</p>

<pre><code class="language-Java">System.out.println(Math.round(0.5));
//输出 1
System.out.println(Math.round(-0.5));
//输出 0
System.out.println(Math.round(-0.51));
//输出 -1
</code></pre>

<p>　　这什么鬼？<br/>
　　Keep Calm and Carry On！<br/>
　　数学上有多种不同的取整方法，比如我们体育老师教的四舍五入。各种取整方法的共同点就是要对真值作近似，于是就会引入偏差。四舍五入显然并不是一种公平的策略（想想0~4的舍和5~9的得）。<br/>
　　有一个叫做银行家舍入(Banker’s Rounding)的东西，不造你听过没，反正我是最近才知道的。事实上.NET和VB6都是默认采用这种方式，而且IEEE 754默认采用之。Banker’s Rounding 也就是<strong>round to even</strong>策略。<br/>
假设当前考虑那位的数字是d（d就是将不被保留的第一位），如果d<5，则舍(round to zero)；如果d>5，则入(round away from zero)；而当d==5时，就要根据d前后的数位来确定往哪边取了。<br/>
1) 如果d之后存在非零的数位，则入；<br/>
2) 如果d之后不存在非零的数位，则看d之前的一位，用c表示：<br/>
　　a.如果c是奇数，则入；<br/>
　　b.如果c是偶数，则舍。</p>

<p>再来一把栗子，对下列数保留0位小数，则第一位小数就是d，整数位就是c：</p>

<pre><code class="language-java">BankRound(0.4)==0,　　BankRound(0.6)==1
BankRound(-0.4)==0,　　BankRound(-0.6)==-1
BankRound(1.5)==2.0,　　BankRound(-1.5)==-2.0
BankRound(2.5)==2.0,　　BankRound(-2.5)==-2.0
BankRound(1.51)==2.0,　　BankRound(-1.51)==-2.0
BankRound(2.51)==3.0,　　BankRound(-2.51)==-3.0
</code></pre>

<p>　　可以看出，Banker’s Rounding对正数和负数的处理是对称的，因此不会引入符号带来的偏差。另外它以均等的几率来舍入数位（考虑c, c有各一半的几率为奇数和偶数），所以多次舍入后与真值的差别较小。<br/>
　　扯了这么多，跟Java的<strong>Math.round( )</strong>有什么关系呢？我也是写到这才发现，好像没什么软关系。因为它并没有遵循Banker’s rounding。而是按照以下策略进行取整：</p>

<p>1)当考虑的数位d不是5，d<5就舍，d>5则入。<br/>
2)当d是5：<br/>
　　a.如果d的右边有非零数位，则入；<br/>
　　b.如果d的右边没有非零数位，则** round to ceiling**，即对负数舍，对正数入。</p>

<p><a href="http://docs.oracle.com/javase/7/docs/api/java/lang/Math.html">Java文档里是这么表述的</a></p>

<p>还有, 在Java里可以使用<strong>BigDecimal</strong>和<strong>RoundingMode</strong>实现更通用的取整方式。</p>

<pre><code class="language-java">double d = -2.5;
BigDecimal bd = new BigDecimal(d);
double nd = bd.setScale(0, RoundingMode.HALF_EVEN).doubleValue();
System.out.println(nd);
//输出 -2.0
</code></pre>

<p><strong>setScale</strong>的第一个参数是保留的小数位数，第二个参数是舍入模式。可选的舍入模式有：<br/>
<strong>HALF_EVEN</strong>, 也就是<strong>银行家</strong>舍入；<br/>
<strong>HALF_UP</strong>, 四舍五入；<br/>
<strong>HALF_DOWN</strong>, 五舍六入；<br/>
<strong>CEILING、FLOOR</strong>, 向正无穷、负无穷方向；<br/>
<strong>UP、DOWN</strong>*, 向零和远离零；<br/>
<strong>UNNECESSARY</strong>, 断言舍入后的值和原值相等，也就是不需要舍入。如果断言错了，抛出<strong>ArithmeticException</strong>异常。</p>

<p>先写到这，有话好好说。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[梯度下降]]></title>
    <link href="http://21stacks.top/14598347945676.html"/>
    <updated>2016-04-05T13:39:54+08:00</updated>
    <id>http://21stacks.top/14598347945676.html</id>
    <content type="html"><![CDATA[
<p>　　梯度下降算法是一种常见的无约束优化问题求解算法。其主要特点有：<br/>
　　1.迭代式，逐步逼近；<br/>
　　2.只能在待优化函数的可导邻域内寻优；<br/>
　　3.沿梯度的反方向搜索；<br/>
　　3.实现相对简单。<br/>
　　设优化目标为<br/>
\[\min_{x}F(x)\qquad (1)\]<br/>
　　\(F(x)\)是\(R^{n}\)上一阶可导函数。现在要求一个\(x\in R^{n}\)，使\(F(x)\)达到极小值。</p>

<span id="more"></span><!-- more -->

<p>　　梯度下降算法基于这样一个事实：</p>

<blockquote>
<p>如果函数\(F(x)\)在点\(x=x_m\)的一个邻域内可微，则当\(x\)沿着这个点的梯度的反方向变化时，\(F(x)\)下降的速度最快。</p>
</blockquote>

<p>　　也就是说，\(x\)应按下式变化：<br/>
\[x_{m+1}=x_m-\gamma \triangledown F(x_m)\qquad (2)\]<br/>
　　其中\(\triangledown F(x_m)\)是\(F(x)\)在\(x_m\)处的梯度；\(\gamma\)是一个较小的系数，控制着\(x\)更新的步长，作为Learning Rate。当\(\gamma\)足够小，有\(F(x_{m+1})\leq F(x_m)\)。梯度下降算法通过迭代的方式逐渐减小\(F(x)\)的值，在每一步迭代中要完成的工作就是求梯度值，以及步长\(\gamma\)。算法的描述如下。</p>

<h4 id="toc_0">算法 Gradient Descent</h4>

<p><strong>输入</strong>：目标函数\(F(x)\)，最大迭代次数\(M\)。<br/>
<strong>输出</strong>：\(F(x)\)的极小值点\(x&#39;\)。</p>

<p>1.初始化\(x_0\)，令其为\(R^{n}\)上的某个点。<br/>
2.对\(m=1,2,...,M\)<br/>
　　a.求梯度\(\triangledown F(x_m)\)；<br/>
　　b.求步长\(\gamma\)；<br/>
　　c.更新\(x\)，令\(x_{m+1}=x_m-\gamma\triangledown\)。<br/>
3.输出\(x&#39;=x^{M}\)。</p>

<p>　　也可以设定一个较小的值\(\varepsilon\)，当\(x\)或\(F(x)\)的更新小于它时，提前结束算法。</p>

<h4 id="toc_1">步长</h4>

<p>　　以上算法对步骤2.b求步长\(\gamma\)做详细描述。确定步长的方法，可以直接预设其为一个很小的正实数、可以以\(\gamma\)为自变量对\(F(x)\)求导以得到一个确切的值、也可以采用线性搜索的方式求一个适当的值。通常，线性搜索是更合理的方式，其计算量不大，找到的值足够好。</p>

<h4 id="toc_2">回溯线性搜索 Backtracking Line Search (BLS)</h4>

<p>　　BLS是一种迭代式的线性搜索方法，可用于梯度下降过程中确定\(\gamma\)的值。令\(\gamma\)为一个较大的值，然后通过一个系数\(\tau \in (0,1)\)来逐步减小\(\gamma\)。</p>

<h5 id="toc_3">算法 BLS</h5>

<p><strong>输入</strong>：\(F(x)\)、\(x_m\)，\(\triangledown F(x_m)=p\)为\(F(x_m)\)的梯度向量，\(\tau \in (0,1)\)，一个控制参数\(c\in (0,1)\)。<br/>
<strong>输出</strong>：\(\gamma&#39;\)。</p>

<p>1.令\(\gamma\)为一个较大值；令\(\alpha= -\parallel p \parallel &lt;0\)；<br/>
2.循环，令<br/>
\[\gamma=\tau\gamma\]<br/>
　直到\(F(x+\gamma \alpha)\leq F(x)+\gamma c \alpha\)。<br/>
3.输出\(\gamma&#39;=\gamma\)。</p>

<h4 id="toc_4">随机梯度下降</h4>

<p>　　当在含多个样本的数据集上使用梯度下降法，参数的更新公式(2)应有以下形式<br/>
\[x_{m+1}=x_m-\gamma \sum_{i=1}^{n}\triangledown F_i(x_m)\qquad (3)\]<br/>
　　这里\(\triangledown F_i(x_m)\)表示第\(i\)个样本上的梯度值，\(n\)是总的样本数。若\(n\)较大，则梯度下降的每一步迭代都是比较耗时的。一种改进的做法是随机梯度下降法(Stochastic Gradient Descent, SGD)。SGD在每一步迭代中都只考虑某个随机抽取的样本子集，极端情况下每次只取一个样本。</p>

<h4 id="toc_5">Why Gradient Descent ?</h4>

<p>　　要求一个函数的极小值，最直观的想法莫过于求目标函数导函数的零点了。为什么我们还需要像梯度下降这样的迭代式算法呢？<br/>
　　梯度下降算法最常用的场景是极小化机器学习模型的损失函数。对于大多数非线性模型而言，损失函数的优化不存在封闭解，因此不能用求导函数零点的方法来解。对于线性模型(待优化参数的线性函数)，存在封闭解，但求封闭解的计算复杂度较高，在实践上通常不易计算。<br/>
　　例如对于我们熟知的线性回归模型，其平方损失函数可以定义为<br/>
\[J(\theta)=\frac{1}{2}\sum_{i=1}^{N}(x_i\theta-y_i)^2\]<br/>
　　其中\(x_i\)是第\(i\)个训练样本，是一个\(M\)维行向量；\(\theta\)是回归模型的参数，是一个\(M\)维列向量。注意这里的\(x\)表示的含义与前文不同，前面我们用了\(x\)来表示待优化(估计)参数。上式也可以写成<br/>
\[J=\frac{1}{2}\sum_{i=1}^{N}[\sum_{j=1}^{M}x_{ij}\theta_j-y_i]^2\]<br/>
优化目标为求<br/>
\[\theta&#39;=arg\min_{\theta}J(\theta)\]<br/>
用最小二乘法求封闭解，对损失函数求导，让导数为0，对\(j=1,2,...M\)有，<br/>
\[\frac{\partial J(\theta)}{\partial \theta_j}=\sum_{i=1}^{N}x_{ij} *(\sum_{k=1}^{M}x_{ik}\theta_k-y_i)=0\]<br/>
整合成矩阵形式有：<br/>
\[\frac{\partial J(\theta)}{\partial \theta}=X^{T}X\theta-X^{T}Y=0\]<br/>
于是得到解<br/>
\[\theta&#39;=(X^{T}X)^{-1}X^{T}Y\]<br/>
　　上式表明，为了求损失函数的极小值点，要求矩阵\(X^{T}X\)的逆矩阵。对于一个\(n\times n\)的矩阵，求逆矩阵运算的时间复杂度为\(O(n^3)\)，当\(n\)较大时，耗时很久。</p>

<h4 id="toc_6">Wrap it up</h4>

<p>　　如果待优化的目标函数是凸函数，则梯度下降算法可以得到全局最优解(Global Optimum)。否则，求得的大多是局部最优。步长和初始点的选择都会影响梯度下降算法的寻优结果。相比于牛顿法，梯度下降的收敛需要更多的迭代次数，但计算更简单。相比于群智能算法，梯度下降算法寻优能力较弱，且只适用于可微目标函数。</p>

<h4 id="toc_7">Reference</h4>

<blockquote>
<p>[1] 李航 统计学习方法<br/>
[2] <a href="https://en.wikipedia.org/wiki/Gradient_descent">Wikipedia: Gradient Descent</a></p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Boosting]]></title>
    <link href="http://21stacks.top/14592400407522.html"/>
    <updated>2016-03-29T16:27:20+08:00</updated>
    <id>http://21stacks.top/14592400407522.html</id>
    <content type="html"><![CDATA[
<p>　　Boosting是一种Adaptive Basis-function Model (ABM)。ABM模型可以用式(1)高度概括：<br/>
\[f(x)=w_0+\sum_{m=1}^{M} w_m \phi_m(x) \qquad(1)\]<br/>
　　这里的\(\phi_m(x)\)是从数据中学习而来的第\(m\)个基本模型(基函数)。ABM通过多个模型的线性组合来得到<strong>非线性</strong>的模型。事实上，决策树就是一种ABM。一棵具有\(M\)个叶子节点的决策树可以表示为：<br/>
\[T(x)=\sum_{m=1}^{M}w_mI(x\in R_m)\qquad (2)\]<br/>
　　\(R_m\)是决策树的第\(m\)个叶节点；\(w_m\)表示第\(m\)个叶节点的标示值(输出)；当样本x属于第\(m\)个叶节点时，函数\(I(x \in R_m)\)输出1，否则输出0。<br/>
　　Boosting是除了决策树以外的另一种常见的ABM模型。Boosting中的基本模型也叫做weak learner。被使用最多的基本模型是CART。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">前向分步算法</h2>

<p>　　为了得到一个ABM模型，需要求数个基函数，以及它们对应的系数。Boosting方法的核心是前向分步算法。前向分步的意思就是，逐步往前构建，且不回头来调整。若最终要达成的模型含有\(M\)个基函数，则前向分步算法要经过\(M\)次迭代。在第\(m\)次(\(0&lt;m\leq M\))迭代时通过以下公式求得\(f_m\)：<br/>
\[f_{m}(x)=f_{m-1}(x)+\alpha_m\phi_m(x) \qquad(3)\]<br/>
而最终的模型就是\(f(x)=f_M(x)\)。这里用\(\alpha_m\)代替了式(1)中的\(w_m\)。<br/>
　　在求\(f_m\)时，我们已经得到了\(f_{m-1}\)。因此只要得到第\(m\)个基函数\(\phi_m(x)\)及其系数\(\alpha_m\)，就可以通过(3)式构造出\(f_m\)。Boosting在第\(m\)次迭代中通过极小化损失函数来求\(f_m(x)\)。其优化目标可用下式表示：<br/>
\[\min_{f_m}=\sum_{i=1}^{N}L(y_i,f_m(x_i))\qquad (4)\]<br/>
　　上式中，\(L\)是损失函数，\(N\)是训练集的大小。具体的Boosting算法有很多种，它们采用了各种不同的损失函数。<br/>
　　把(3)带入(4)式，我们的优化目标可以写成：<br/>
\[(\phi_m,\alpha_m)=\min_{\phi,\alpha}\sum_{i=1}^{N}L(y_i,f_{m-1}(x)+\alpha\phi(x)) \qquad(5)\]<br/>
　　通过以上表述可以知道，Boosting是一种贪心策略，在迭代的过程中逐步逼近优化目标，求得模型的不是Global Optimum。</p>

<h2 id="toc_1">AdaBoost</h2>

<p>　　AdaBoost(Adaptive Boost)是最常见的一种Boosting算法。它被认为是最好的out-of-the-box(咋翻译？)分类算法。AdaBoost为每个训练样本赋予了不同的权值，表示它们的重要性(分类的难易程度)。在训练过程中，随着迭代的进行，难以分类的样本权值会变得更高，使模型逐步倾向这些样本。</p>

<h4 id="toc_2">推理</h4>

<p>　　一下讨论基于二分类问题，令\(y_i\in\{-1,1\}\)。<br/>
　　AdaBoost采用的损失函数是指数损失函数。在前向分步算法的第\(m\)步，优化的目标函数就是式(6)：<br/>
\[L_m(\phi)=\sum_{i=1}^{N} exp[-y_i(f_{m-1}(x_i)+\alpha\phi(x_i))]\qquad(6)\]<br/>
　　下面要描述的是如何通过优化(6)来求\(\alpha\)和\(\phi(x)\)。<br/>
　　首先，令<br/>
\[w_{m,i}=exp[-y_if_{m-1}(x_i)]\qquad(7)\]<br/>
\(w_{m,i}\)表示开始第\(m\)次迭代时，第\(i\)个训练样本的权重。于是(6)可以表示为：<br/>
\[L_m(\phi)=\sum_{i=1}^{N}w_{m,i}exp(-\alpha y_i \phi(x_i))\qquad(8)\]<br/>
此时如果把训练样本输入到基本模型\(\phi(x)\)，则有的样本会被正确分类，另一些则被错误分类。在上式中把这两类样本分开来，可以改写成：<br/>
\[L_m=e^{-\alpha}\sum_{y_i=\phi(x_i)}^{}w_{m,i}+e^{\alpha}\sum_{y_i\neq \phi(x_i)}^{}w_{m,i}\\\<br/>
=(e^{\alpha}-e^{-\alpha})\sum_{i=1}^{N}w_{m,i}I(y_i\neq \phi(x_i))+e^{-\alpha}\sum_{i=1}^{N}w_{m,i}<br/>
\qquad(9)\]<br/>
因为\(\alpha\geq 0\)，所以\((e^{\alpha}-e^{-\alpha})\geq 0\)。于是可得，能使\(L_m\)极小化的\(\phi_m\)就如<strong>(10)</strong>所示：<br/>
\[\phi_m(x)=arg\min_{\phi}\sum_{i=1}^{N}w_{m,i}I(y_i \neq \phi(x_i))\qquad(10)\]<br/>
上式中，\(\sum_{i=1}^{N}w_{m,i}I(y_i\neq\phi_m(x))\)可以定义为\(\phi_M(x)\)在训练集上的加权分类误差\(e_m\)。<br/>
\[e_m=\sum_{i=1}^{N}w_{m,i}I(y_i\neq\phi_m(x))\qquad(11)\]<br/>
　　接着来求\(\phi_m(x)\)的系数\(\alpha_m\)。在式(9)上对\(\alpha\)求导，令导数为0：<br/>
\[\frac{d L_m}{d \alpha}=e^{\alpha}\sum_{i=1}^{N}w_{m,i}I(y_i\neq\phi_m(x))-e^{-\alpha}\sum_{i=1}^{N}w_{m,i}I(y_i=\phi_m(x_i))=0\qquad(12)\]<br/>
化简可得：<br/>
\[\alpha=\frac{1}{2}ln{\frac{\sum_{i=1}^{N}w_{m,i}I(y_i=\phi_m(x_i))}{\sum_{i=1}^{N}w_{m,i}I(y_i\neq\phi_m(x_i))}}\qquad(13)\]<br/>
式(13)中，分子是所有被\(\phi_m(x)\)正确分类的样本的权值之和，分母是所有被\(\phi_m(x)\)误分类的样本的权值之和，因此有：<br/>
\[\alpha_m=\frac{1}{2}ln{\frac{1-e_m}{e_m}}\qquad(14)\]<br/>
　　权值\(\alpha_m\)表示模型\(\phi_m(x)\)在最终的组合模型中的话语权大小。当\(e_m&lt;0.5\)时，\(\alpha_m&gt;0\)，且\(\alpha_m\)随着\(e_m\)的减小而增大，即误差越小的模型越权威。<br/>
　　到此我们找到了极小化\(L_m\)的weak learner \(\phi_m(x)\)和它的权重系数\(\alpha_m\)。顺势可以使用式(3)求得在第\(m\)次迭代时的\(f_m(x)\)。<br/>
　　前面我们令\(w_{m,i}=exp[-y_i f_{m-1}(x_i)]\)，即每一次都使用上一次迭代得到的\(f_{m-1}(x)\)来更新训练集样本的权值。若已求得\(f_{m}(x)\)，则在第\({m+1}\)次迭代求\(w_{m+1,i}\)的方法如下：<br/>
\[w_{m+1,i}=exp[-y_i f_{m}(x_i)]\\<br/>
=exp[-y_i(f_{m-1}(x_i) +\alpha_m\phi_m(x_i)  )]\\<br/>
=w_{m,i} * e^{-y_i \alpha_m \phi_m(x_i)}\qquad\quad(15)\]<br/>
　　上式的效果就是让那些在\(\phi_m(x)\)上被正确分类的样本对应的权值变小，使错误分类的样本的权值变大。这就使得后续的学习偏重于处理较难分类的样本。<br/>
　　为了让\(w_{m,i}\)成为一种概率分布，还要进一步正规化：<br/>
\[w_{m+1,i}=\frac{w_{m,i}exp[-y_i\alpha_m\phi_m(x_i)]}{Z_m}\qquad(16)\\<br/>
Z_m=\sum_{i=1}^{N}w_{m,i}exp[-y_i\alpha_m\phi_m(x_i)]\qquad(17)<br/>
\]<br/>
　　在第一次迭代时要用到\(f_0(x)\)，因此预先定义\(f_0(x)=0\)(一个常数)。于是有\(w_{1,i}=exp[-y_if_0(x_i)]=1\)，对\(i=1,2,...N\)。正规化后有\(w_{1,i}=\frac{1}{N}\)。下一部分总结性地描述了AdaBoost算法。<br/>
　　</p>

<h4 id="toc_3">算法 Adaboost</h4>

<p><strong>输入</strong>：训练数据集\(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，其中\(x_i\in\chi \subseteq R^{n}\)，\(y_i\in\{-1,+1\}\)。以及弱基本模型\(\phi(x)\)；迭代次数\(M\)。<br/>
<strong>输出</strong>：强分类器\(\Phi(x)\)。</p>

<p>1.初始化训练样本的权值分布：<br/>
\[D_1=(w_{11},...,w_{1i},...w_{1N}),\quad w_{1i}=\frac{1}{N},\quad i=1,2,...N\]<br/>
2.对\(m=1,2,...M\)<br/>
　　a.使用训练数据集和它的权值分布\(D_m\)训练学习模型，得到弱基本模型\(\phi_m(x)\)，此模型满足式(10)。<br/>
　　b.根据式(11)计算\(\phi_m(x)\)在训练数据集上的带权误差<br/>
　　\[e_m=\sum_{i=1}^N w_{m,i}I(\phi_m(x_i)\neq y_i)\]<br/>
　　c.根据式(14)计算\(\phi_m(x)\)的权重系数<br/>
　　\[\alpha_m=\frac{1}{2}ln\frac{1-e_m}{e_m}\]<br/>
　　d.根据式(16)和(17)更新训练数据集的权值分布<br/>
\[D_{m+1}=(w_{m+1,1},...,w_{m+1,i},...w_{m+1,N})\\\<br/>
w_{m+1,i}=\frac{w_{m,i} exp(-y_i \alpha_m \phi_m(x_i))}{Z_m}\\\<br/>
Z_m=\sum_{i=1}^{N} w_{m,i}exp(-y_i \alpha_m h_m(x_i))\]<br/>
3.组合得到最终分类器<br/>
\[\Phi(x)=sign(f_M(x))=sign(\sum_{m=1}^{M}\alpha_m \phi_m(x))\]</p>

<h4 id="toc_4">局限性</h4>

<p>　　AdaBoost容易偏向于难以分类的样本，因此对Outlier很敏感，容易过拟合。</p>

<h2 id="toc_5">其他Boosting算法</h2>

<h4 id="toc_6">L2Boosting</h4>

<p>　　在Boosting的前向分步算法中，若采用平方误差损失函数，就得到了L2Boosting模型。在L2Boosting模型中，weak learner的权重系数通常都设为1。因此在前向分步算法的第\(m\)次迭代时要优化的目标就是求：<br/>
\[\phi_m=arg\min_{\phi}\sum_{i=1}^{N}L(y_i,f_{m-1}(x_i)+\phi(x_i))\] <br/>
这里\(L(y,f_{m-1}(x)+\phi(x))=[y-f_{m-1}(x)-\phi(x)]^2\)。也就是说，要寻求一个\(\phi_m\)，使得\(\phi_m(x)\)尽可能地靠近(拟合)\(y-f_{m-1}(x)\)。令\(r=y-f_{m-1}(x)\)为当前模型(\(f_{m-1}(x)\))拟合训练样本的<strong>残差</strong>。在第\(m\)次迭代时，样本\(i\)对应的残差为：<br/>
\[r_{m,i}=y_i-f_{m-1}(x_i)\]<br/>
　　L2Boosting算法的迭代过程，就是通过拟合残差来学习新的weak learner，并把这些weak learner线性组合以得到强模型。</p>

<h2 id="toc_7">梯度提升Gradient Boosting</h2>

<p>　　Boosting算法可以采用各种不同的损失函数。这些算法可以归结为一种统一的形式，即梯度提升算法。梯度提升算法可以使用任意的合理的<strong>可微</strong>损失函数。对Boosting模型，我们在每一次迭代时都是求\(\phi_m(x)\)和\(\alpha_m\)，尽可能地使<br/>
　　\[f_{m+1}(x)=f_m(x)+\alpha_m\phi_m(x)\rightarrow y\]<br/>
即尽可能地让\(\alpha_m(x_i)\phi_m(x_i)\rightarrow y_i-f_m(x_i)\)。<br/>
上式右边正是残差。如果采用损失函数：<br/>
\[L=\frac{1}{2}\sum_{i=1}^{N}(y_i-f_m(x_i))^2\]<br/>
则此残差就是损失函数的负梯度值：<br/>
\[-\frac{\partial L}{\partial f_m(x_i)}=y-f_m(x_i)\]<br/>
　　对于一般化的损失函数，梯度提升算法采用损失函数负梯度值作为残差的近似值(<strong>伪残差</strong>)。在训练样本(输入向量)及其伪残差形成的数据集上训练新的weak learner。<br/>
　　像其他的Boosting算法一样，梯度提升算法也采用前向分步算法。在第\(m\)次迭代时，要求weak learner \(\phi_m(x)\)以及它对应的权重系数\(\alpha_m\)，以极小化损失函数为目标。梯度提升通过拟合伪残差来得到\(\phi_m(x)\)，然后求解一维的(以\(\alpha_m\)为自变量)优化问题得到\(\alpha_m\)。<br/>
　　</p>

<h4 id="toc_8">算法 Gradient Boosting</h4>

<p><strong>输入</strong>：训练数据集\(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，其中\(x_i\in\chi \subseteq R^{n}\)。以及weak learner模型\(\phi(x)\)；迭代次数\(M\)。<br/>
<strong>输出</strong>：强模型\(f_M(x)\)。</p>

<p>1.初始化模型\(f_0(x)\)(一个常数)：<br/>
\[f_0(x)=arg\min_{\alpha}\sum_{i=1}^{N}L(y_i,\alpha)\]<br/>
2.对\(m=1,2,...M\)：<br/>
　　a.求各训练样本的伪残差：<br/>
\[r_{m,i}=-[\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)}]_{f(x)=f_{m-1}(x)}\]<br/>
　　b.在训练集\(\{(x_1,r_{m,1}),(x_2,r_{m,2}),...(x_N,r_{m,N})\}\)上训练基本模型，得到\(\phi_m(x)\)。<br/>
　　c.解一维优化问题，求\(\alpha_m\)<br/>
\[\alpha_m=arg\min_{\alpha}\sum_{i=1}^{N}L(y_i,f_{m-1}(x_i)+\alpha\phi_m(x_i))\]<br/>
　　d.更新模型<br/>
\[f_m(x)=f_{m-1}(x)+\alpha_m\phi_m(x)\]<br/>
3.输出 \(f_M(x)\)。</p>

<h4 id="toc_9">正则化</h4>

<p>　　为了提高模型的泛化能力，可以采用多种正则化策略。<br/>
　　1.限制迭代次数\(M\)。迭代次数决定了基本模型的数量。较大的\(M\)能减小训练误差，但容易过拟合。可以单独采用一个验证集，在迭代过程中评估泛化误差。<br/>
　　2.Shrinkage。给新学得的模型加一个较小的系数，以限制其对最终模型的影响：<br/>
\[f_m(x)=f_{m-1}(x)+ v\alpha_m\phi_m(x)\qquad 0&lt;v\leq 1\]<br/>
这个\(v\)也就是learning rate。较小的\(v\)会减慢算法的收敛速度，但能得到更好的模型。<br/>
　　2.随机梯度提升。在迭代过程中每次都从原始训练集选择一个子集。通常抽取原数据集一半大小的子集。<br/>
　　3.当采用决策树作为基本模型时，可以限制叶节点内的样本数。若节点样本数小于一定值，则不再划分。</p>

<h2 id="toc_10">GBDT</h2>

<p>　　Gradient Boosting如果采用决策树作为基本模型，就得到了Gradient Boosting Decision Tree(GBDT)。也就是说在梯度提升算法的迭代过程中，每次要找的基本模型就是一棵树。树的叶节点们把输入空间划分成多个子区域，并对各子区域分别估计响应值(如对回归问题求落入该区域样本y值的平均，对分类问题采取多数投票)。设\(\phi_m(x)\)是一棵决策树，它把输入空间划分成\(J\)个区域，则\(\phi_m(x)\)可以表示为<br/>
\[\phi_m(x)=\sum_{j=1}^{J}c_{m,j}I(x\in R_{m,j})\]<br/>
这里\(R_{m,j}\)表示树\(\phi_m(x)\)的第\(j\)个叶节点(输入空间子区域)，\(c_{m,j}\)是其对应的响应值。<br/>
　　这也就是说，GBDT对梯度提升算法做了改进，不再是给模型\(\phi_m(x)\)一个参数\(\alpha_m\)，而是给它的所有叶节点分别赋予一个参数。<br/>
　　当设置\(J=2\)，就是采用决策桩(Decision Stump)作为基本模型。通常设置\(4\leq J\leq 8\)。</p>

<h4 id="toc_11">算法 GBDT</h4>

<p><strong>输入</strong>：训练数据集\(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，其中\(x_i\in\chi \subseteq R^{n}\)。以及weak learner 决策树模型\(\phi(x)\)；迭代次数\(M\)。<br/>
<strong>输出</strong>：\(f_M(x)\)。</p>

<p>1.初始化模型\(f_0(x)\)：<br/>
\[f_0(x)=arg\min_{\alpha}\sum_{i=1}^{N}L(y_i,\alpha)\]<br/>
2.对\(m=1,2,...M\)：<br/>
　　a.求各训练样本的伪残差：<br/>
\[r_{m,i}=-[\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)}]_{f(x)=f_{m-1}(x)}\]<br/>
　　b.在训练集\(\{(x_1,r_{m,1}),(x_2,r_{m,2}),...(x_N,r_{m,N})\}\)上训练，得到决策树模型\(\phi_m(x)\)，它有\(J\)个子区域。<br/>
　　c.对\(j=1,2,...J\)，计算<br/>
　　\[c_{m,j}=arg\min_{c}\sum_{x_i\in R_{m,j}}L(y_i, (f_{m-1}+c))\]<br/>
　　d.更新模型<br/>
\[f_m(x)=f_{m-1}(x)+\sum_{j=1}^{J}c_{m,j}I(x\in R_{m,j})\]<br/>
3.输出模型<br/>
\[f_M(x)=\sum_{m=1}^{M}\phi_m(x)\\\<br/>
=\sum_{m=1}^{M}\sum_{j=1}^{J}c_{m,j}I(x\in R_{m,j})\]</p>

<h2 id="toc_12">Reference</h2>

<blockquote>
<p>[1] 李航，统计学习方法<br/>
[2] Murphy, Machine Learning: A Probabilistic Perspective</p>
</blockquote>

<p>　　</p>

<p>　</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bagging]]></title>
    <link href="http://21stacks.top/14592424184360.html"/>
    <updated>2016-03-29T17:06:58+08:00</updated>
    <id>http://21stacks.top/14592424184360.html</id>
    <content type="html"><![CDATA[
<p>　　一种组合学习模型。通过从原始训练数据集里有放回(with replacement)地抽取数据样本，来构造新的训练集。每得到一个新的训练集就在其上训练一个模型。重复多次，得数个模型。采用求平均或Major Vote来组合这些模型，得到最终的输出模型。<br/>
　　新构造的训练集与原始训练集有着相同数量的样本，设为\(N\)。则每构造一个新训练集，原始训练集中的单个样本被抽取(即至少被抽中一次)的概率是：<br/>
　　\[p=1-(1-\frac{1}{N})^{N}\]</p>

<span id="more"></span><!-- more -->

<p>　　注意到<br/>
　　\[\lim_{N\rightarrow \infty}p=\lim_{N\rightarrow \infty}1-[(1+\frac{1}{-N})^{-N}]^{-1}=1-\frac{1}{e}\]<br/>
　　因此当\(N\)足够大时有\(p\approx 0.632\)。因此每构造一个训练集，原始训练集里有大约\(63\%\)的样本会被抽中。</p>

<h2 id="toc_0">缺陷</h2>

<p>　　对于组合学习模型而言，基本模型之间的相关性越低，组合后的效果越好。Bagging策略的基本模型之间相关性较强，因此性能不佳。</p>

<h2 id="toc_1">改进</h2>

<p>　　应设法降低训练集之间的相关性。<strong>随机森林</strong>是对Bagging的一种改进。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[随机森林]]></title>
    <link href="http://21stacks.top/14591708106411.html"/>
    <updated>2016-03-28T21:13:30+08:00</updated>
    <id>http://21stacks.top/14591708106411.html</id>
    <content type="html"><![CDATA[
<p>　　随机森林是以决策树为基本模型的Bagging策略。通过两个层次的随机性来降低基本模型的相关性，从而提高组合模型的性能。<br/>
　　1.在训练每棵树时，从训练数据集中有放回地抽取样本；<br/>
　　2.每次分裂时随机选取一个特征子集(随机子空间).</p>

<span id="more"></span><!-- more -->

<p><strong>算法：</strong><br/>
<strong>输入</strong>：训练数据集\(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，其中\(x_i\in\chi \subseteq R^{n}\)，样本含有\(n\)个属性，\(y_i\in\{-1,+1\}\)。以及基本模型\(h(x)\)(决策树)、基本模型的数量\(M\)、特征子集的大小\(sn\)。<br/>
<strong>输出</strong>：强模型\(H(x)\)。<br/>
1.对于\(m=1,2,...M\)<br/>
　　a.有放回地随机抽取训练数据集\(T_i\)；<br/>
　　b.用\(T_i\)训练\(h_i(x)\)，每次分裂时随机选取特征子集；<br/>
2.组合这M个模型，得强模型。</p>

<p><strong>Caution:</strong><br/>
1.对于分类问题，可以令特征子集的大小为\(sn=\sqrt{n}\)；对于回归问题可以令\(sn=\frac{n}{3}\)。<br/>
2.对分类问题，最终模型可以是M个模型的Major Vote；对于回归问题，可以对它们的结果求平均。<br/>
<strong>3.</strong>可以用随机森林来评估属性的重要程度。</p>

<p><strong>Feature Importance</strong><br/>
　　随机森林在建立每一棵树时都临时抽取一个训练集。因此原始训练集里的样本\(x\)可能只参与了一部分树的建立，而在建立另一些树的时候没有被使用。对于样本\(x\)，如果用那些它没有参与建立的树来处理它(分类或回归)，就会存在误差；在所有它没参与建立的树上的误差之和，就是Out-of-bag error (oob)。随机森林利用oob来评估属性的重要性，其算法描述如下。<br/>
　　<br/>
<strong>输入</strong>：训练数据集\(T\)，在\(T\)上得到的随机森林模型\(H(x)\)。<br/>
<strong>输出</strong>：属性重要性。<br/>
1.计算\(T\)中样本的平均误差\(oob\).<br/>
2.对\(j=1,2,...n\)<br/>
　　a.对\(T\)中所有样本的属性\(j\)做Permute(Shuffle)，得到临时样本集合\(T&#39;\)，求\(T&#39;\)的Out-of-bag error \(oob_j\).<br/>
　　b.属性\(j\)的重要性得分是\(S_j=oob-oob_j\)<br/>
3.输出所有属性的得分\(S\)。值越大越重要。</p>

<h2 id="toc_0">Reference</h2>

<blockquote>
<p>[1] 李航 统计学习方法<br/>
[2] Murphy, Machine Learning: A Probabilistic Perspective</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Stacked Generalization]]></title>
    <link href="http://21stacks.top/14591708106532.html"/>
    <updated>2016-03-28T21:13:30+08:00</updated>
    <id>http://21stacks.top/14591708106532.html</id>
    <content type="html"><![CDATA[
<p>　　使用多层模型，前一层的输出作为特征，当作后一层的输入。以两层模型为例。第一层使用两种分类器，生成两种meta-feature；第二层使用一个分类器，以这些meta-features为特征生成分类结果。训练集和测试集都要经历这两个层次。在第一层，对于单个分类器，可以采用k-fold来生成这个分类器对应的meta-feature。整个过程可以用以下两图表示，这里采用了2-fold。</p>

<span id="more"></span><!-- more -->

<p>　　<img src="http://7xrz9i.com1.z0.glb.clouddn.com/ensemblestackedGeneralization-Train.png" alt=""/><br/>
　　<img src="http://7xrz9i.com1.z0.glb.clouddn.com/ensemblestackedGeneralization-Test.png" alt=""/><br/>
　　C1和C2是第一层采用的分类器。<br/>
　　对<strong>训练集</strong>的操作：<br/>
　　1.划分训练集P为两个fold，PA，PB。<br/>
　　2.对于C1，生成F1：<br/>
　　　　以PA为训练集训练它，然后将C1作用于PB，生成部分meta-feature F1B；<br/>
　　　　以PB为训练集训练它，然后将C1作用于PA，生成部分meta-feature F1A；<br/>
　　　　组合以上两部分meta-feature，生成F1，a column。<br/>
　　3.对C2，生成F2：过程类似2。<br/>
　　4.组合F1和F2，生成含有两种feature（Attribute）的新数据集F，y还是原来的训练集的y。<br/>
　　对<strong>测试集</strong>：<br/>
　　同样要生成两种meta-feature。<br/>
　　1.可以用整个训练集分别训练C1和C2，然后将C1和C2作用于测试集。就像上图2那样。<br/>
　　2.也可以把上图1中得到的两个(多个)C1都作用于测试集，投票或求评价得到TF1；用同样的方法得到TF2。<br/>
　　3.组合TF1，TF2，生成TF，含两种属性。 </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[得见东江湖]]></title>
    <link href="http://21stacks.top/14598276464760.html"/>
    <updated>2016-04-05T11:40:46+08:00</updated>
    <id>http://21stacks.top/14598276464760.html</id>
    <content type="html"><![CDATA[
<p><img src="http://7xrz9i.com1.z0.glb.clouddn.com/%E4%B8%9C%E6%B1%9F%E6%B9%96.jpg" alt=""/></p>

<span id="more"></span><!-- more -->

<blockquote>
<p>2015年9月12日 手机摄于东江湖.</p>
</blockquote>

<p>　　我总认为，近处的风景随时去看都可以，因此在长春待了四年，从未到过长白山。我还认为，太远的风景不值得为之舟车劳累长途跋涉，如今身在广州，长白山不去也罢。<br/>
　　生于湘南林邑，而这是我首次得以近览东江湖，若不是亲人邀请盛情难却，也不得成行。九月的天气已近秋，加之数日的连绵细雨，湖上竟刮起凛冽寒风。我们一群老少爷们在这风中冻得瑟瑟发抖，唯年近八旬的三姨奶奶一人岿然屹立，迎风眺望，那意气风发的劲头着实让人惊叹。她年轻时在南车工作，吃了很多苦；退休后学起了国画、京剧；还独自一人览遍大江南北，在广袤的草原上跃马扬鞭，在翻腾的大海上引吭高歌。这种气质，我羡慕，学不来。<br/>
　　等我不搬砖了，就找条小街，开个照相馆，就叫老曾照相馆。你看，人老去的样子千姿百态，也不知道会有几人光顾我的照相馆。管他呢，到那时候老子肯定很有钱。<br/>
　　<br/>
　　<br/>
　　<br/>
　　<br/>
　　</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[广美的气质]]></title>
    <link href="http://21stacks.top/14598440012972.html"/>
    <updated>2016-04-05T16:13:21+08:00</updated>
    <id>http://21stacks.top/14598440012972.html</id>
    <content type="html"><![CDATA[
<p><img src="http://7xrz9i.com1.z0.glb.clouddn.com/cold-guangmeiDSCF1485%E5%89%AF%E6%9C%AC.jpg" alt=""/></p>

<span id="more"></span><!-- more -->

<p><img src="http://7xrz9i.com1.z0.glb.clouddn.com/cold-guangmeiDSCF1490%E5%89%AF%E6%9C%AC.jpg" alt=""/></p>

<p><img src="http://7xrz9i.com1.z0.glb.clouddn.com/cold-guangmeiDSCF1480%E5%89%AF%E6%9C%AC.jpg" alt=""/></p>

<blockquote>
<p>2014年12月13日 摄于广州美术学院.</p>
</blockquote>

<p>　　十多年前我在一所县级中学里上初中，经常莫名其妙地考年级第一，那时候我梦想成为画家。后来去了市里读高中，我努力了好几把都没能考进前十，所以那时候我喜欢去网吧玩游戏。上大学了，班上同学的通信原理课都特认真，但我还是觉得编程更有意思。<br/>
　　人都各有成长，但总会在某个时期，痴迷于一种和别人不一样的自我。<br/>
　　<br/>
　　<br/>
　　<br/>
　　</p>

]]></content>
  </entry>
  
</feed>
