<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[]]></title>
  <link href="http://21stacks.top/atom.xml" rel="self"/>
  <link href="http://21stacks.top/"/>
  <updated>2016-04-10T23:07:22+08:00</updated>
  <id>http://21stacks.top/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[粒子群优化算法]]></title>
    <link href="http://21stacks.top/14605499748686.html"/>
    <updated>2016-04-13T20:19:34+08:00</updated>
    <id>http://21stacks.top/14605499748686.html</id>
    <content type="html"><![CDATA[
<p>　　粒子群优化算法(Partlcle Swarm Optimization, PSO)是一种基于群体智能的搜索算法。 PSO具有参数配置简单、搜索性能好、可适应性强等优势，因而得到了广泛的应用。本文将从优化问题的基本概念说起，介绍基本PSO算法原理以及它的一些变体，并简单描述其应用场景。</p>

<h2 id="toc_0">Motivation</h2>

<h3 id="toc_1">什么是优化问题</h3>

<p>　　优化，就是要在多种方案中寻找最好的方案。比如有的妹子们出门见男盆友之前恨不得把所有衣服都试一遍，以找到一种最满意的搭配。不过一般情况下她们可能看哪件衣服都觉得不完美，然后要么选择一件还算顺眼的凑活一下，要么愉快地开始了网购...就像妹子们选衣服那样，典型的优化问题通常是不太可能在可接受的时间之内找到一个全局最优解(Global Optimum)的，所以只能想办法在合理的时间内找到一个可接受的解(Local Optimum)。旅行商问题(TSP)、神经网络的训练、无线传感器网络(WSN)的任务调度等，都是常见的优化问题。</p>

<span id="more"></span><!-- more -->

<h3 id="toc_2">优化算法</h3>

<p>　　先明确几个概念。<br/>
　　什么是<strong>可行解</strong>？回到妹子挑衣服的问题，只要还能穿的衣服，不管好不好看挨不挨冻，都算是可行解。<br/>
　　什么是<strong>解空间</strong>？所有可行解所构成的集合就是解空间，这个“空间”是抽象的，可能很多维，甚至可能是离散而非连续的。优化算法要做的，就是在解空间中的各个可行解中，尽可能地找到更好的解。这是一个搜索过程，所以优化算法也叫搜索算法(不是Searching Engine那种搜索)。<br/>
　　什么是<strong>目标函数</strong>？不同的优化算法有着不同的搜索策略，因此可能在不同的问题上表现出各自的优越性。另外需要明确，怎样的解算是一个好的解？我们必须确定一个标准来评价解的好坏。这通常要根据问题本身的特性来建立一个目标函数(Objective Function)。相比于试衣服时的标准(好看)而言，我们的目标函数是要有明确的数学定义的。因此或许对于前面这个例子，可以改用回头率、男朋友的心跳频率等可量化的标准来作为目标函数。于是优化算法要做的就是对目标函数的解空间寻优。在训练神经网络时，以损失函数(Cost Function)\(J(W,b)\)为目标函数，优化目标就是要极小化损失函数的值。<br/>
　　典型的优化算法有经典的模拟退火、梯度下降等。还有遗传算法、蚁群算法、粒子群优化算法等群智能算法，它们基于对生物群体行为的认知、抽象、借鉴。啊...神奇的大自然...</p>

<h2 id="toc_3">粒子群优化算法简介</h2>

<h3 id="toc_4">起源</h3>

<p>　　粒子群算法源于对鸟群行为的研究。群居的鸟类通常要倾巢出动去寻找食物。对于在鸟群中的一只小小鸟(它名叫Birdy)来说，它处在空间中的某个位置(可以用经度，维度，海拔来衡量)；它在飞行着，因此有速度(包括速率大小和方向)；它当前的速度和位置，决定了它下一时刻会处在什么位置。Birdy是一直有主见的鸟，它有着自己的当前飞行速度；它很聪明，能记住自己曾经到过的位置中哪些可能有丰富的食物；而且它是跟着三姑四婆七舅姥爷一起出门的，它也知道大家各自找到的位置中哪个是食物最丰富的。Birdy的飞行就依靠着三个信息的指引，最终它和亲戚们合力找到了一个可以满足它们食物需求的地方。对以上的描述做一个抽象。在解空间中随机放置一定数量的粒子，每一个粒子所在的位置就是它所代表的解；同时粒子是在运动的，它有速度，会在解空间中移动。每个粒子的移动过程就是根据当前速度和位置去往下一刻的位置。粒子们作为一个群体是相互协同和制约的。每一个粒子要根据三个因素来确定它下一刻的速度：自己当前的速度，这代表了它本身的搜索能力；自己目前为止找到的最好位置，这是它的认知部分；目前位置整个群体所能找到的最好位置，这是社会部分。 </p>

<h2 id="toc_5">细节</h2>

<p>　　PSO中单个粒子速度和位置的更新可以用下面两式表达：<br/>
\[V^{i+1}=\omega V^{i}+c_1r_1(pbest-X^{i})+c_2r_2(gbest-X^{i})\qquad(1)\]<br/>
\[X^{i+1}=X^{i}+V^{i+1}\qquad(2)\]<br/>
　　其中V是粒子的速度，X则是粒子的位置，它们都是多维的向量或矩阵；i表示迭代次数。公式(1)右边的多项式中的三项分别是当前速度，代表粒子本身的搜索能力；当前位置与粒子自身的历史最佳位置(pbest)的差距，代表其自我认知；当前位置与整个群体的历史最佳位置(gbest)的差距，代表粒子的社会性。粒子下一刻的速度是这个三个速度的和。\(\omega\)、\(c_1\)和\(c_2\)是预先设置的参数，调整它们的大小可以改变后两个部分的影响力(权重)。\(r_1\)和\(r_2\)是两个(0,1)之间的随机数，每次更新速度都要重新生成。粒子的位置更新由公式(2)表示，这一步只需给位置加上一个更新后的速度。粒子群算法的执行过程要经历很多次迭代，每一次迭代的过程就是更新粒子速度和位置的过程，并且如果产生了更好的位置，还要更新pbest和gbest。下面两图分别表示二维平面上粒子的速度和位置更新过程。<br/>
<img src="http://7xrz9i.com1.z0.glb.clouddn.com/psoPSO%E9%80%9F%E5%BA%A6%E6%9B%B4%E6%96%B0.jpg?imageView/2/w/500" alt=""/><br/>
<img src="http://7xrz9i.com1.z0.glb.clouddn.com/psoPSO%E4%BD%8D%E7%BD%AE%E6%9B%B4%E6%96%B0.jpg?imageView/2/w/500" alt="&quot;图1&quot;"/><br/>
　　\(c_1\)、\(c_2\)的常用设置都是2.0。\(\omega\) 的值通常设为(0,1)之间的一个数，它也可以随着迭代次数增加而不断减小。随着迭代的进行，个体位置\(X\)与\(pbest\)和\(gbest\)的差距会越来越小。也就是说，后两项对速度的影响会越来越小。而且速度在每一次迭代都会被乘以一个小于零的\(\omega\) ，因此速度会趋于零。当速度不断趋于零的时候，粒子的位置变动也越来越慢，直至停滞不动。这就是粒子群的收敛过程。<br/>
下面的伪代码概括了PSO的执行过程。<br/>
{% codeblock %}<br/>
配置参数：种群规模 SwarmSize; 最大迭代次数 MaxIter<br/>
Init: 生成SwarmSize个粒子，随机初始化它们的位置和速度<br/>
Get fitness for each particle<br/>
Get gbest<br/>
Set pbest as the current position for each particle<br/>
IterNum=0<br/>
while IterNum&lt;MaxIter<br/>
    for each particle<br/>
      renew V<br/>
      renew X<br/>
    renew pbest<br/>
    renew gbest<br/>
return gbest<br/>
{% endcodeblock %}<br/>
　　对于PSO这类基于群体智能的搜索算法，应该尽量保证个体的多样性。所谓多样性，就是说个体之间存在着差异，各种各样的个体都有。公式(1)中的随机数\(r_1\)和\(r_2\)就是一种提高多样性的机制。个体的多样性越好，它们在解空间中的分布就越广，群体的搜索能力就越强，陷入局部最优解的可能性就越小。这里存在着两个矛盾：一方面我们希望尽可能地保持粒子的多样性，以提高群体都搜索能力；另一方面我们希望粒子的运动是趋于收敛的，也就是希望粒子的位置会在合理的时间内逐渐趋同。很多对于PSO算法的改进就是着眼于对这个矛盾的均衡。</p>

<h2 id="toc_6">改进</h2>

<p>　　对于PSO的改进大多围绕提高粒子多样性和保持一定的收敛速度来进行。这里主要介绍三种：引入变异、邻域PSO、综合学习(Comprehensive Learning)。</p>

<h3 id="toc_7">引入变异</h3>

<p>　　变异的概念来源于生物进化(依旧是神奇的大自然)。在物种进化的过程中主要起作用的因素有：自然选择，适者生存，优胜劣汰；个体之间的基因交流，重组出新的基因；个体自身的变异产生新的基因。变异发生的概率很低，但对于物种多样性有着非常重要的意义。对于生物进化的认知、抽象、运用，得出了著名的遗传算法(Genetic Algorithm, GA)。我们可以从GA中借鉴变异操作，来提高PSO中群体的多样性。我们预先设定一个较小的变异率参数muRate(比如0.02)，在每次迭代中随机产生一个数，如果这个数小于muRate，则进行变异操作。具体的变异操作可以是对位置X增减一个随机值，可以随机重置某些维度，甚至可以重新随机初始化整个粒子。变异操作为陷入局部最优解的群体提供了跳变，从而提高了群体的搜索能力。</p>

<h3 id="toc_8">邻域PSO</h3>

<p>　　实验表明，公式(1)中的最后一项，即历史最优解，对于整个群体的影响力非常大。它很有可能把群体带向一个并不是很好的位置，使得群体陷于局部最优解。因此可以通过减缓历史最优解信息的传递速度，来保持粒子多样性。这个思想产生了各种基于邻域的PSO算法。它们的共同特点是，把最后一项的群体历史最优改成个体邻域内的历史最优解:<br/>
\[V^{i+1}=\omega V^{i}+c_1r_1(pbest-X^{i})+c_2r_2(lbest-X^{i})\qquad(3)\]<br/>
对于一个粒子来说，lbest就是它处在的邻域范围内的各个粒子目前为止所得到的最优解。常见的邻域有环形邻域、随机邻域、von Neumann邻域。</p>

<h3 id="toc_9">综合学习</h3>

<p>　　综合学习策略(Comprehensive Learning，CL)是由梁静(J.J.Liang，现在应该在郑州大学)提出来的。CL同样认为在基本PSO算法中，gbest的影响力过于强大，容易很快把群体带到一个局部最优解位置，因此应该想办法限制gbest的影响。怎么限制？大姐说了，咱直接把它去掉。于是就得到了一个只有两项的速度更新公式:<br/>
\[V^{i+1}=\omega V^{i}+cr(pbest_f-X^{i})\qquad(4)\]<br/>
这里的pbest也不再是原来的pbest。它是一个组合体，虽然形态和普通的pbest还是一样的，但它的不同维度可能来自不同的粒子。通过把较好的粒子的某些维度重组在一起，得到了新的\(pbest_f\)。它掌握着来自整个群体的好的信息，因此有能力指引着群体去往更好的位置。而当种群中个体越来越接近，它们的速度也逐渐趋于零，于是慢慢地收敛了。关于CL的更多细节请参考附录[1]。<br/>
　　以上的改进都会在一定程度上使群体的收敛速度变慢，因此需要更多的迭代次数。对于解空间不复杂的问题，综合学习的优势并不突出。而当被用来解决各种复杂多峰的优化问题时，它在寻优能力方面的优势就很明显了。</p>

<h2 id="toc_10">组合优化</h2>

<p>　　以上描述的都是对于连续问题的优化算法。针对离散问题，PSO也有对应的版本。对于离散PSO(PBSO)，粒子的位置是离散的值。基本BPSO的粒子的编码为0-1编码，即粒子中的每一维度非0即1。而速度的各个维度依然的连续的，因此我们需要一个函数，将连续的速度值映射成离散的位置值。最常用的映射函数是\(sigmoid\)函数，于是使用以下两个公式更新粒子的位置：<br/>
\[S({V_j}^{i})=\frac{1}{1+e^{-{V_j}^{i}}}\qquad(5)\]<br/>
\[{X_j}^{i+1}=\begin{cases}<br/>
0 &amp; \text{ if } random\geqslant S({V_j}^{i}) \\\ <br/>
1 &amp; \text{ if } random&lt; S({V_j}^{i})<br/>
\end{cases}\qquad(6)\]  </p>

<p>这里\(V^{i}_{j}\)表示在第i次迭代时粒子速度的第j维。\(sigmoid\)函数的形态入下图所示：<br/>
<img src="http://7xrz9i.com1.z0.glb.clouddn.com/psoSigmoid.png" alt=""/><br/>
观察其函数形态可以发现，当速度趋于0的时候，其函数值趋于0.5。这也就是说，对应维度的位置值是0还是1，是等可能的。这并不符合我们所预期的目标：当速度趋于收敛的时候位置也趋于不变。因此一个更合理的方案是采用一种在输入为0时其函数值也为0的函数，例如\(T(X)=\left | tanh(X) \right |\)。这类函数的形态像一个V形：<br/>
<img src="http://7xrz9i.com1.z0.glb.clouddn.com/psoVshaped.png" alt=""/><br/>
如果采用V形函数，则位置更新方式也要跟着改为下式，使得当速度趋于0时，位置趋于不变：<br/>
\[{X_j}^{i+1}=\begin{cases}<br/>
0 &amp; \text{ if } random\leqslant T({V_j}^{i}) and {V_j}^{i}\leqslant 0\\\ <br/>
1 &amp; \text{ if } random\leqslant T({V_j}^{i}) and {V_j}^{i}&gt; 0 \\\ <br/>
{X_j}^{i} &amp; \text{ if } random&gt; T({V_j}^{i}) <br/>
\end{cases}\]<br/>
　　这里还要重点安利一种神奇的离散PSO框架，那就是我师兄(兼现任带头大哥)提出的基于集合的离散PSO(Set-based PSO，SPSO)。SPSO的框架非常灵活，可以很好地整合其他算法思想，比如结合综合学习策略；且其编码方式可以自如地根据实际问题来设计。详见附录[2]。</p>

<h1 id="toc_11">应用</h1>

<p>PSO的应用场景非常广泛，可谓上天下海无所不能。</p>

<h2 id="toc_12">人工神经网络</h2>

<p>　　对于神经网络的训练，最小化损失函数是个显而易见的优化问题，因此可以用PSO之类的优化算法来做。详见本博客的<a href="http://zxcoder.xyz/2016/03/18/Neural-Network-PSO/">另一篇博文</a>。</p>

<h2 id="toc_13">K-中心聚类</h2>

<p>　　K-means的最大缺陷之一就是对于初始选择中心的敏感性，使用<a href="">PSO聚类</a>可以很好地解决这个问题。</p>

<blockquote>
<p><a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1637688&amp;newsearch=true&amp;queryText=comprehensive%20learning%20particle%20swarm">1. Comprehensive Learing PSO</a><br/>
<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5299261&amp;newsearch=true&amp;queryText=set-based%20particle%20swarm">2. Set-based PSO</a><br/>
　　</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SSE的背后]]></title>
    <link href="http://21stacks.top/14600116978074.html"/>
    <updated>2016-04-07T14:48:17+08:00</updated>
    <id>http://21stacks.top/14600116978074.html</id>
    <content type="html"><![CDATA[
<h3 id="toc_0">定义</h3>

<p>　　Sum of Square Error (SSE)代价函数用于衡量一个模型对数据的拟合程度。其形式化的表述为<br/>
\[C(\theta)=\frac{1}{2}\sum_{i=1}^{N}(y_i-h_{\theta}(x_i))^2\qquad(1)\]</p>

<span id="more"></span><!-- more -->

<p>　　其中\((x_i, y_i)\)是数据样本，\(x_i\in R^n\)；\(h_{\theta}(x)\)是以\(\theta\)为参数的模型，假设(hypothesis)。在前面加一个系数\(\frac{1}{2}\)的为了方便处理某些运算。注意还有一个常见的概念，平均平方误差(Mean Square Error, MSE)，它是SSE在数据集上的均值，是以平方损失函数为基础的经验风险函数。MSE是一种与数据集大小无关的误差衡量，本质上跟SSE并没有什么软区别。<br/>
\[MSE=\frac{1}{2N}\sum_{i=1}^{N}(y_i-h_{\theta}(x_i))^2\qquad(2)\]</p>

<h3 id="toc_1">直观含义</h3>

<p>　　从式(1)可以清楚地看到，SSE直观地表示了模型\(h_{\theta}(x)\)对\(y\)的拟合程度的好坏。\(SSE\geq 0\)，且拟合程度越好SSE越小，一个完美拟合的模型会使SSE为0。在对数据集建立分类或回归模型时，我们追求的目标是尽可能地找到一个模型，使得<br/>
\[y=h_{\theta}(x)\qquad(3)\]<br/>
　　很多算法对模型的学习策略都是通过极小化SSE来实现的。不幸的是，我们总不能完美找到一个这样的模型。不能的意思有两层。一是说能力不够，受制于所选模型特性等因素，并不总能得到一个完美的拟合，例如无法用感知机模型对线性不可分的数据完美地划分。 二是说不应该，在训练数据集上完美拟合的模型通常是过拟合的泛化能力不好的模型。后者的主要原因是训练数据中存在的噪声，以及模型自身的缺陷。因此通常情况下，由模型得出的预测值与\(y\)之间的关系是这样的<br/>
\[y=h_{\theta}(x)+\epsilon\qquad(4)\]<br/>
　　\(\epsilon\)表示\(\hat{y}=h_{\theta}(x)\)对\(y\)的误差。在回归分析中称\(\epsilon=y-h_{\theta}(x)\)为残差，而式(1)也被称为残差平方和(Residual Sum of Square, RSS)。可以采用最小二乘法来求解极小化RSS问题。若模型是参数\(\theta\)的线性函数，可以求得封闭解；否则可以采用迭代方式求解。</p>

<h3 id="toc_2">从参数估计的角度来看</h3>

<p>　　为什么通过极小化SSE得到的模型是好的？除了直观感觉，我们也可以从参数估计的角度做一些推理。这里我们关注的是式(4)中的误差<br/>
\[\epsilon=y-h_{\theta}(x)\qquad(5)\]<br/>
　　对于一组数据\(\{(x_1,y_1),(x_2,y_2),...,(x_i,y_i),...,(x_N,y_N)\}\)，可以得到一组误差值\(\{\epsilon_1,\epsilon_2,...,\epsilon_i,...,\epsilon_N \}\)。通常认为这个误差集里的数据是源于总体分布\(f(x;\theta)\)的抽样，它们独立同分布。因此所有\(\epsilon\)的联合概率密度为<br/>
\[f(\epsilon_1,...,\epsilon_N;\theta)=f(\epsilon_1;\theta)f(\epsilon_2;\theta)\cdot\cdot\cdot f(\epsilon_N;\theta)\qquad(6)\]<br/>
　　记\(L(\epsilon_1,...,\epsilon_N;\theta)=f(\epsilon_1,...,\epsilon_N;\theta)\)为似然函数，\(\theta\)是待估计的参数。若\(L(\epsilon_1,...,\epsilon_N;\theta_1)&gt;L(\epsilon_1,...,\epsilon_N;\theta_2)\)，我们说当已知\(\{\epsilon_1,...,\epsilon_N\}\)时，待估计参数\(\theta\)是\(\theta_1\)的可能性大于\(\theta_2\)。因此我们有了一个优化目标：要寻求一个\(\theta&#39;\)，使\(L\)尽可能大。<br/>
　　进一步假设\(\epsilon_i\)是均值为0的高斯噪声(Or, what else can it be ?)；其方差为某\(\sigma^2\)。即\(\epsilon\)的分布的概率密度函数为<br/>
\[f(\epsilon|\theta)=(\frac{1}{2\pi\sigma^2})^{\frac{1}{2}}exp(-\frac{\epsilon^2}{2\sigma^2})\qquad(7)\]<br/>
于是，似然函数可写成<br/>
\[L(\theta)=\prod_{i=1}^{N}(\frac{1}{2\pi\sigma^2})^{\frac{1}{2}}exp(-\frac{\epsilon_i^2}{2\sigma^2})\qquad(8)\]<br/>
为了方便处理，对式(8)左右两边去自然对数，\(g(z)=lnz\)是\(z\)的单调递增函数，因此优化目标不变。整理得<br/>
\[lnL(\theta)=-\frac{1}{2\sigma^2}\sum_{i=1}^{N}\epsilon^2-\frac{N}{2}ln(2\pi\sigma^2)\qquad(9)\]<br/>
将式(5)代入(9)，得<br/>
\[lnL(\theta)=-\frac{1}{2\sigma^2}\sum_{i=1}^{N}(y_i-h_{\theta(x_i)})^2-\frac{N}{2}ln(2\pi\sigma^2)\qquad(10)\]<br/>
式(10)中，等号右边的第二项与\(\theta\)无关，因此要极大化\(lnL(\theta)\)就是要极大化等号右边第一项。由于\(\sigma^2\)是某个正实数，因此我们的优化目标就相当于求<br/>
\[\theta&#39;=arg\min_{\theta}\frac{1}{2}\sum_{i=1}^{N}(y_i-h_{\theta}(x_i))^2\qquad(11)\]<br/>
式(11)正是极小化SSE的方法所寻求的，也就是说，极小化SSE等价于极大似然估计。前文假设\(\epsilon\)服从高斯分布。高斯分布属于指数族分布。参考文献[4]指出，当观测样本来源于指数族分布，辅以适当条件，最小二乘法就等价于极大似然估计。<br/>
　　对于线性回归模型，\(h_{\theta}(x)=\theta^Tx\)，代入(11)得<br/>
\[\theta&#39;=arg\min_{\theta}\frac{1}{2}\sum_{i=1}^{N}(y_i-\theta^Tx_i)^2\qquad(12)\]<br/>
求解(12)式既可以采用求导函数零点求封闭解，也可以使用迭代式的解法如<a href="http://acesmg.github.io/14598347945676.html">梯度下降法</a>。</p>

<h3 id="toc_3">Reference</h3>

<blockquote>
<p>[1] 陈希孺，概率论与数理统计<br/>
[2] Wikipedia: <a href="https://en.wikipedia.org/wiki/Maximum_likelihood">Maximum Likelihood</a><br/>
[3] Murphy, Machine Learning: A Probabilistic Perspective.<br/>
[4] A.Charnes etc, <a href="http://www.tandfonline.com/doi/abs/10.1080/01621459.1976.10481508">The Equivalence of Generalized Least Squares and Maximum Likelihood Estimates in the Exponential Family</a></p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[梯度下降]]></title>
    <link href="http://21stacks.top/14598347945676.html"/>
    <updated>2016-04-05T13:39:54+08:00</updated>
    <id>http://21stacks.top/14598347945676.html</id>
    <content type="html"><![CDATA[
<p>　　梯度下降算法是一种常见的无约束优化问题求解算法。其主要特点有：<br/>
　　1.迭代式，逐步逼近；<br/>
　　2.只能在待优化函数的可导邻域内寻优；<br/>
　　3.沿梯度的反方向搜索；<br/>
　　3.实现相对简单。<br/>
　　设优化目标为<br/>
\[\min_{x}F(x)\qquad (1)\]<br/>
　　\(F(x)\)是\(R^{n}\)上一阶可导函数。现在要求一个\(x\in R^{n}\)，使\(F(x)\)达到极小值。</p>

<span id="more"></span><!-- more -->

<p>　　梯度下降算法基于这样一个事实：</p>

<blockquote>
<p>如果函数\(F(x)\)在点\(x=x_m\)的一个邻域内可微，则当\(x\)沿着这个点的梯度的反方向变化时，\(F(x)\)下降的速度最快。</p>
</blockquote>

<p>　　也就是说，\(x\)应按下式变化：<br/>
\[x_{m+1}=x_m-\gamma \triangledown F(x_m)\qquad (2)\]<br/>
　　其中\(\triangledown F(x_m)\)是\(F(x)\)在\(x_m\)处的梯度；\(\gamma\)是一个较小的系数，控制着\(x\)更新的步长，作为Learning Rate。当\(\gamma\)足够小，有\(F(x_{m+1})\leq F(x_m)\)。梯度下降算法通过迭代的方式逐渐减小\(F(x)\)的值，在每一步迭代中要完成的工作就是求梯度值，以及步长\(\gamma\)。算法的描述如下。</p>

<h4 id="toc_0">算法 Gradient Descent</h4>

<p><strong>输入</strong>：目标函数\(F(x)\)，最大迭代次数\(M\)。<br/>
<strong>输出</strong>：\(F(x)\)的极小值点\(x&#39;\)。</p>

<p>1.初始化\(x_0\)，令其为\(R^{n}\)上的某个点。<br/>
2.对\(m=1,2,...,M\)<br/>
　　a.求梯度\(\triangledown F(x_m)\)；<br/>
　　b.求步长\(\gamma\)；<br/>
　　c.更新\(x\)，令\(x_{m+1}=x_m-\gamma\triangledown\)。<br/>
3.输出\(x&#39;=x^{M}\)。</p>

<p>　　也可以设定一个较小的值\(\varepsilon\)，当\(x\)或\(F(x)\)的更新小于它时，提前结束算法。</p>

<h4 id="toc_1">步长</h4>

<p>　　以上算法对步骤2.b求步长\(\gamma\)做详细描述。确定步长的方法，可以直接预设其为一个很小的正实数、可以以\(\gamma\)为自变量对\(F(x)\)求导以得到一个确切的值、也可以采用线性搜索的方式求一个适当的值。通常，线性搜索是更合理的方式，其计算量不大，找到的值足够好。</p>

<h4 id="toc_2">回溯线性搜索 Backtracking Line Search (BLS)</h4>

<p>　　BLS是一种迭代式的线性搜索方法，可用于梯度下降过程中确定\(\gamma\)的值。令\(\gamma\)为一个较大的值，然后通过一个系数\(\tau \in (0,1)\)来逐步减小\(\gamma\)。</p>

<h5 id="toc_3">算法 BLS</h5>

<p><strong>输入</strong>：\(F(x)\)、\(x_m\)，\(\triangledown F(x_m)=p\)为\(F(x_m)\)的梯度向量，\(\tau \in (0,1)\)，一个控制参数\(c\in (0,1)\)。<br/>
<strong>输出</strong>：\(\gamma&#39;\)。</p>

<p>1.令\(\gamma\)为一个较大值；令\(\alpha= -\parallel p \parallel &lt;0\)；<br/>
2.循环，令<br/>
\[\gamma=\tau\gamma\]<br/>
　直到\(F(x+\gamma \alpha)\leq F(x)+\gamma c \alpha\)。<br/>
3.输出\(\gamma&#39;=\gamma\)。</p>

<h4 id="toc_4">随机梯度下降</h4>

<p>　　当在含多个样本的数据集上使用梯度下降法，参数的更新公式(2)应有以下形式<br/>
\[x_{m+1}=x_m-\gamma \sum_{i=1}^{n}\triangledown F_i(x_m)\qquad (3)\]<br/>
　　这里\(\triangledown F_i(x_m)\)表示第\(i\)个样本上的梯度值，\(n\)是总的样本数。若\(n\)较大，则梯度下降的每一步迭代都是比较耗时的。一种改进的做法是随机梯度下降法(Stochastic Gradient Descent, SGD)。SGD在每一步迭代中都只考虑某个随机抽取的样本子集，极端情况下每次只取一个样本。</p>

<h4 id="toc_5">Why Gradient Descent ?</h4>

<p>　　要求一个函数的极小值，最直观的想法莫过于求目标函数导函数的零点了。为什么我们还需要像梯度下降这样的迭代式算法呢？<br/>
　　梯度下降算法最常用的场景是极小化机器学习模型的损失函数。对于大多数非线性模型而言，损失函数的优化不存在封闭解，因此不能用求导函数零点的方法来解。对于线性模型(待优化参数的线性函数)，存在封闭解，但求封闭解的计算复杂度较高，在实践上通常不易计算。<br/>
　　例如对于我们熟知的线性回归模型，其平方损失函数可以定义为<br/>
\[J(\theta)=\frac{1}{2}\sum_{i=1}^{N}(x_i\theta-y_i)^2\]<br/>
　　其中\(x_i\)是第\(i\)个训练样本，是一个\(M\)维行向量；\(\theta\)是回归模型的参数，是一个\(M\)维列向量。注意这里的\(x\)表示的含义与前文不同，前面我们用了\(x\)来表示待优化(估计)参数。上式也可以写成<br/>
\[J=\frac{1}{2}\sum_{i=1}^{N}[\sum_{j=1}^{M}x_{ij}\theta_j-y_i]^2\]<br/>
优化目标为求<br/>
\[\theta&#39;=arg\min_{\theta}J(\theta)\]<br/>
用最小二乘法求封闭解，对损失函数求导，让导数为0，对\(j=1,2,...M\)有，<br/>
\[\frac{\partial J(\theta)}{\partial \theta_j}=\sum_{i=1}^{N}x_{ij} *(\sum_{k=1}^{M}x_{ik}\theta_k-y_i)=0\]<br/>
整合成矩阵形式有：<br/>
\[\frac{\partial J(\theta)}{\partial \theta}=X^{T}X\theta-X^{T}Y=0\]<br/>
于是得到解<br/>
\[\theta&#39;=(X^{T}X)^{-1}X^{T}Y\]<br/>
　　上式表明，为了求损失函数的极小值点，要求矩阵\(X^{T}X\)的逆矩阵。对于一个\(n\times n\)的矩阵，求逆矩阵运算的时间复杂度为\(O(n^3)\)，当\(n\)较大时，耗时很久。</p>

<h4 id="toc_6">Wrap it up</h4>

<p>　　如果待优化的目标函数是凸函数，则梯度下降算法可以得到全局最优解(Global Optimum)。否则，求得的大多是局部最优。步长和初始点的选择都会影响梯度下降算法的寻优结果。相比于牛顿法，梯度下降的收敛需要更多的迭代次数，但计算更简单。相比于群智能算法，梯度下降算法寻优能力较弱，且只适用于可微目标函数。</p>

<h4 id="toc_7">Reference</h4>

<blockquote>
<p>[1] 李航 统计学习方法<br/>
[2] <a href="https://en.wikipedia.org/wiki/Gradient_descent">Wikipedia: Gradient Descent</a></p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Boosting]]></title>
    <link href="http://21stacks.top/14592400407522.html"/>
    <updated>2016-03-29T16:27:20+08:00</updated>
    <id>http://21stacks.top/14592400407522.html</id>
    <content type="html"><![CDATA[
<p>　　Boosting是一种Adaptive Basis-function Model (ABM)。ABM模型可以用式(1)高度概括：<br/>
\[f(x)=w_0+\sum_{m=1}^{M} w_m \phi_m(x) \qquad(1)\]<br/>
　　这里的\(\phi_m(x)\)是从数据中学习而来的第\(m\)个基本模型(基函数)。ABM通过多个模型的线性组合来得到<strong>非线性</strong>的模型。事实上，决策树就是一种ABM。一棵具有\(M\)个叶子节点的决策树可以表示为：<br/>
\[T(x)=\sum_{m=1}^{M}w_mI(x\in R_m)\qquad (2)\]<br/>
　　\(R_m\)是决策树的第\(m\)个叶节点；\(w_m\)表示第\(m\)个叶节点的标示值(输出)；当样本x属于第\(m\)个叶节点时，函数\(I(x \in R_m)\)输出1，否则输出0。<br/>
　　Boosting是除了决策树以外的另一种常见的ABM模型。Boosting中的基本模型也叫做weak learner。被使用最多的基本模型是CART。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">前向分步算法</h2>

<p>　　为了得到一个ABM模型，需要求数个基函数，以及它们对应的系数。Boosting方法的核心是前向分步算法。前向分步的意思就是，逐步往前构建，且不回头来调整。若最终要达成的模型含有\(M\)个基函数，则前向分步算法要经过\(M\)次迭代。在第\(m\)次(\(0&lt;m\leq M\))迭代时通过以下公式求得\(f_m\)：<br/>
\[f_{m}(x)=f_{m-1}(x)+\alpha_m\phi_m(x) \qquad(3)\]<br/>
而最终的模型就是\(f(x)=f_M(x)\)。这里用\(\alpha_m\)代替了式(1)中的\(w_m\)。<br/>
　　在求\(f_m\)时，我们已经得到了\(f_{m-1}\)。因此只要得到第\(m\)个基函数\(\phi_m(x)\)及其系数\(\alpha_m\)，就可以通过(3)式构造出\(f_m\)。Boosting在第\(m\)次迭代中通过极小化损失函数来求\(f_m(x)\)。其优化目标可用下式表示：<br/>
\[\min_{f_m}=\sum_{i=1}^{N}L(y_i,f_m(x_i))\qquad (4)\]<br/>
　　上式中，\(L\)是损失函数，\(N\)是训练集的大小。具体的Boosting算法有很多种，它们采用了各种不同的损失函数。<br/>
　　把(3)带入(4)式，我们的优化目标可以写成：<br/>
\[(\phi_m,\alpha_m)=\min_{\phi,\alpha}\sum_{i=1}^{N}L(y_i,f_{m-1}(x)+\alpha\phi(x)) \qquad(5)\]<br/>
　　通过以上表述可以知道，Boosting是一种贪心策略，在迭代的过程中逐步逼近优化目标，求得模型的不是Global Optimum。</p>

<h2 id="toc_1">AdaBoost</h2>

<p>　　AdaBoost(Adaptive Boost)是最常见的一种Boosting算法。它被认为是最好的out-of-the-box(咋翻译？)分类算法。AdaBoost为每个训练样本赋予了不同的权值，表示它们的重要性(分类的难易程度)。在训练过程中，随着迭代的进行，难以分类的样本权值会变得更高，使模型逐步倾向这些样本。</p>

<h4 id="toc_2">推理</h4>

<p>　　一下讨论基于二分类问题，令\(y_i\in\{-1,1\}\)。<br/>
　　AdaBoost采用的损失函数是指数损失函数。在前向分步算法的第\(m\)步，优化的目标函数就是式(6)：<br/>
\[L_m(\phi)=\sum_{i=1}^{N} exp[-y_i(f_{m-1}(x_i)+\alpha\phi(x_i))]\qquad(6)\]<br/>
　　下面要描述的是如何通过优化(6)来求\(\alpha\)和\(\phi(x)\)。<br/>
　　首先，令<br/>
\[w_{m,i}=exp[-y_if_{m-1}(x_i)]\qquad(7)\]<br/>
\(w_{m,i}\)表示开始第\(m\)次迭代时，第\(i\)个训练样本的权重。于是(6)可以表示为：<br/>
\[L_m(\phi)=\sum_{i=1}^{N}w_{m,i}exp(-\alpha y_i \phi(x_i))\qquad(8)\]<br/>
此时如果把训练样本输入到基本模型\(\phi(x)\)，则有的样本会被正确分类，另一些则被错误分类。在上式中把这两类样本分开来，可以改写成：<br/>
\[L_m=e^{-\alpha}\sum_{y_i=\phi(x_i)}^{}w_{m,i}+e^{\alpha}\sum_{y_i\neq \phi(x_i)}^{}w_{m,i}\\\<br/>
=(e^{\alpha}-e^{-\alpha})\sum_{i=1}^{N}w_{m,i}I(y_i\neq \phi(x_i))+e^{-\alpha}\sum_{i=1}^{N}w_{m,i}<br/>
\qquad(9)\]<br/>
因为\(\alpha\geq 0\)，所以\((e^{\alpha}-e^{-\alpha})\geq 0\)。于是可得，能使\(L_m\)极小化的\(\phi_m\)就如<strong>(10)</strong>所示：<br/>
\[\phi_m(x)=arg\min_{\phi}\sum_{i=1}^{N}w_{m,i}I(y_i \neq \phi(x_i))\qquad(10)\]<br/>
上式中，\(\sum_{i=1}^{N}w_{m,i}I(y_i\neq\phi_m(x))\)可以定义为\(\phi_M(x)\)在训练集上的加权分类误差\(e_m\)。<br/>
\[e_m=\sum_{i=1}^{N}w_{m,i}I(y_i\neq\phi_m(x))\qquad(11)\]<br/>
　　接着来求\(\phi_m(x)\)的系数\(\alpha_m\)。在式(9)上对\(\alpha\)求导，令导数为0：<br/>
\[\frac{d L_m}{d \alpha}=e^{\alpha}\sum_{i=1}^{N}w_{m,i}I(y_i\neq\phi_m(x))-e^{-\alpha}\sum_{i=1}^{N}w_{m,i}I(y_i=\phi_m(x_i))=0\qquad(12)\]<br/>
化简可得：<br/>
\[\alpha=\frac{1}{2}ln{\frac{\sum_{i=1}^{N}w_{m,i}I(y_i=\phi_m(x_i))}{\sum_{i=1}^{N}w_{m,i}I(y_i\neq\phi_m(x_i))}}\qquad(13)\]<br/>
式(13)中，分子是所有被\(\phi_m(x)\)正确分类的样本的权值之和，分母是所有被\(\phi_m(x)\)误分类的样本的权值之和，因此有：<br/>
\[\alpha_m=\frac{1}{2}ln{\frac{1-e_m}{e_m}}\qquad(14)\]<br/>
　　权值\(\alpha_m\)表示模型\(\phi_m(x)\)在最终的组合模型中的话语权大小。当\(e_m&lt;0.5\)时，\(\alpha_m&gt;0\)，且\(\alpha_m\)随着\(e_m\)的减小而增大，即误差越小的模型越权威。<br/>
　　到此我们找到了极小化\(L_m\)的weak learner \(\phi_m(x)\)和它的权重系数\(\alpha_m\)。顺势可以使用式(3)求得在第\(m\)次迭代时的\(f_m(x)\)。<br/>
　　前面我们令\(w_{m,i}=exp[-y_i f_{m-1}(x_i)]\)，即每一次都使用上一次迭代得到的\(f_{m-1}(x)\)来更新训练集样本的权值。若已求得\(f_{m}(x)\)，则在第\({m+1}\)次迭代求\(w_{m+1,i}\)的方法如下：<br/>
\[w_{m+1,i}=exp[-y_i f_{m}(x_i)]\\<br/>
=exp[-y_i(f_{m-1}(x_i) +\alpha_m\phi_m(x_i)  )]\\<br/>
=w_{m,i} * e^{-y_i \alpha_m \phi_m(x_i)}\qquad\quad(15)\]<br/>
　　上式的效果就是让那些在\(\phi_m(x)\)上被正确分类的样本对应的权值变小，使错误分类的样本的权值变大。这就使得后续的学习偏重于处理较难分类的样本。<br/>
　　为了让\(w_{m,i}\)成为一种概率分布，还要进一步正规化：<br/>
\[w_{m+1,i}=\frac{w_{m,i}exp[-y_i\alpha_m\phi_m(x_i)]}{Z_m}\qquad(16)\\<br/>
Z_m=\sum_{i=1}^{N}w_{m,i}exp[-y_i\alpha_m\phi_m(x_i)]\qquad(17)<br/>
\]<br/>
　　在第一次迭代时要用到\(f_0(x)\)，因此预先定义\(f_0(x)=0\)(一个常数)。于是有\(w_{1,i}=exp[-y_if_0(x_i)]=1\)，对\(i=1,2,...N\)。正规化后有\(w_{1,i}=\frac{1}{N}\)。下一部分总结性地描述了AdaBoost算法。<br/>
　　</p>

<h4 id="toc_3">算法 Adaboost</h4>

<p><strong>输入</strong>：训练数据集\(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，其中\(x_i\in\chi \subseteq R^{n}\)，\(y_i\in\{-1,+1\}\)。以及弱基本模型\(\phi(x)\)；迭代次数\(M\)。<br/>
<strong>输出</strong>：强分类器\(\Phi(x)\)。</p>

<p>1.初始化训练样本的权值分布：<br/>
\[D_1=(w_{11},...,w_{1i},...w_{1N}),\quad w_{1i}=\frac{1}{N},\quad i=1,2,...N\]<br/>
2.对\(m=1,2,...M\)<br/>
　　a.使用训练数据集和它的权值分布\(D_m\)训练学习模型，得到弱基本模型\(\phi_m(x)\)，此模型满足式(10)。<br/>
　　b.根据式(11)计算\(\phi_m(x)\)在训练数据集上的带权误差<br/>
　　\[e_m=\sum_{i=1}^N w_{m,i}I(\phi_m(x_i)\neq y_i)\]<br/>
　　c.根据式(14)计算\(\phi_m(x)\)的权重系数<br/>
　　\[\alpha_m=\frac{1}{2}ln\frac{1-e_m}{e_m}\]<br/>
　　d.根据式(16)和(17)更新训练数据集的权值分布<br/>
\[D_{m+1}=(w_{m+1,1},...,w_{m+1,i},...w_{m+1,N})\\\<br/>
w_{m+1,i}=\frac{w_{m,i} exp(-y_i \alpha_m \phi_m(x_i))}{Z_m}\\\<br/>
Z_m=\sum_{i=1}^{N} w_{m,i}exp(-y_i \alpha_m h_m(x_i))\]<br/>
3.组合得到最终分类器<br/>
\[\Phi(x)=sign(f_M(x))=sign(\sum_{m=1}^{M}\alpha_m \phi_m(x))\]</p>

<h4 id="toc_4">局限性</h4>

<p>　　AdaBoost容易偏向于难以分类的样本，因此对Outlier很敏感，容易过拟合。</p>

<h2 id="toc_5">其他Boosting算法</h2>

<h4 id="toc_6">L2Boosting</h4>

<p>　　在Boosting的前向分步算法中，若采用平方误差损失函数，就得到了L2Boosting模型。在L2Boosting模型中，weak learner的权重系数通常都设为1。因此在前向分步算法的第\(m\)次迭代时要优化的目标就是求：<br/>
\[\phi_m=arg\min_{\phi}\sum_{i=1}^{N}L(y_i,f_{m-1}(x_i)+\phi(x_i))\] <br/>
这里\(L(y,f_{m-1}(x)+\phi(x))=[y-f_{m-1}(x)-\phi(x)]^2\)。也就是说，要寻求一个\(\phi_m\)，使得\(\phi_m(x)\)尽可能地靠近(拟合)\(y-f_{m-1}(x)\)。令\(r=y-f_{m-1}(x)\)为当前模型(\(f_{m-1}(x)\))拟合训练样本的<strong>残差</strong>。在第\(m\)次迭代时，样本\(i\)对应的残差为：<br/>
\[r_{m,i}=y_i-f_{m-1}(x_i)\]<br/>
　　L2Boosting算法的迭代过程，就是通过拟合残差来学习新的weak learner，并把这些weak learner线性组合以得到强模型。</p>

<h2 id="toc_7">梯度提升Gradient Boosting</h2>

<p>　　Boosting算法可以采用各种不同的损失函数。这些算法可以归结为一种统一的形式，即梯度提升算法。梯度提升算法可以使用任意的合理的<strong>可微</strong>损失函数。对Boosting模型，我们在每一次迭代时都是求\(\phi_m(x)\)和\(\alpha_m\)，尽可能地使<br/>
　　\[f_{m+1}(x)=f_m(x)+\alpha_m\phi_m(x)\rightarrow y\]<br/>
即尽可能地让\(\alpha_m(x_i)\phi_m(x_i)\rightarrow y_i-f_m(x_i)\)。<br/>
上式右边正是残差。如果采用损失函数：<br/>
\[L=\frac{1}{2}\sum_{i=1}^{N}(y_i-f_m(x_i))^2\]<br/>
则此残差就是损失函数的负梯度值：<br/>
\[-\frac{\partial L}{\partial f_m(x_i)}=y-f_m(x_i)\]<br/>
　　对于一般化的损失函数，梯度提升算法采用损失函数负梯度值作为残差的近似值(<strong>伪残差</strong>)。在训练样本(输入向量)及其伪残差形成的数据集上训练新的weak learner。<br/>
　　像其他的Boosting算法一样，梯度提升算法也采用前向分步算法。在第\(m\)次迭代时，要求weak learner \(\phi_m(x)\)以及它对应的权重系数\(\alpha_m\)，以极小化损失函数为目标。梯度提升通过拟合伪残差来得到\(\phi_m(x)\)，然后求解一维的(以\(\alpha_m\)为自变量)优化问题得到\(\alpha_m\)。<br/>
　　</p>

<h4 id="toc_8">算法 Gradient Boosting</h4>

<p><strong>输入</strong>：训练数据集\(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，其中\(x_i\in\chi \subseteq R^{n}\)。以及weak learner模型\(\phi(x)\)；迭代次数\(M\)。<br/>
<strong>输出</strong>：强模型\(f_M(x)\)。</p>

<p>1.初始化模型\(f_0(x)\)(一个常数)：<br/>
\[f_0(x)=arg\min_{\alpha}\sum_{i=1}^{N}L(y_i,\alpha)\]<br/>
2.对\(m=1,2,...M\)：<br/>
　　a.求各训练样本的伪残差：<br/>
\[r_{m,i}=-[\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)}]_{f(x)=f_{m-1}(x)}\]<br/>
　　b.在训练集\(\{(x_1,r_{m,1}),(x_2,r_{m,2}),...(x_N,r_{m,N})\}\)上训练基本模型，得到\(\phi_m(x)\)。<br/>
　　c.解一维优化问题，求\(\alpha_m\)<br/>
\[\alpha_m=arg\min_{\alpha}\sum_{i=1}^{N}L(y_i,f_{m-1}(x_i)+\alpha\phi_m(x_i))\]<br/>
　　d.更新模型<br/>
\[f_m(x)=f_{m-1}(x)+\alpha_m\phi_m(x)\]<br/>
3.输出 \(f_M(x)\)。</p>

<h4 id="toc_9">正则化</h4>

<p>　　为了提高模型的泛化能力，可以采用多种正则化策略。<br/>
　　1.限制迭代次数\(M\)。迭代次数决定了基本模型的数量。较大的\(M\)能减小训练误差，但容易过拟合。可以单独采用一个验证集，在迭代过程中评估泛化误差。<br/>
　　2.Shrinkage。给新学得的模型加一个较小的系数，以限制其对最终模型的影响：<br/>
\[f_m(x)=f_{m-1}(x)+ v\alpha_m\phi_m(x)\qquad 0&lt;v\leq 1\]<br/>
这个\(v\)也就是learning rate。较小的\(v\)会减慢算法的收敛速度，但能得到更好的模型。<br/>
　　2.随机梯度提升。在迭代过程中每次都从原始训练集选择一个子集。通常抽取原数据集一半大小的子集。<br/>
　　3.当采用决策树作为基本模型时，可以限制叶节点内的样本数。若节点样本数小于一定值，则不再划分。</p>

<h2 id="toc_10">GBDT</h2>

<p>　　Gradient Boosting如果采用决策树作为基本模型，就得到了Gradient Boosting Decision Tree(GBDT)。也就是说在梯度提升算法的迭代过程中，每次要找的基本模型就是一棵树。树的叶节点们把输入空间划分成多个子区域，并对各子区域分别估计响应值(如对回归问题求落入该区域样本y值的平均，对分类问题采取多数投票)。设\(\phi_m(x)\)是一棵决策树，它把输入空间划分成\(J\)个区域，则\(\phi_m(x)\)可以表示为<br/>
\[\phi_m(x)=\sum_{j=1}^{J}c_{m,j}I(x\in R_{m,j})\]<br/>
这里\(R_{m,j}\)表示树\(\phi_m(x)\)的第\(j\)个叶节点(输入空间子区域)，\(c_{m,j}\)是其对应的响应值。<br/>
　　这也就是说，GBDT对梯度提升算法做了改进，不再是给模型\(\phi_m(x)\)一个参数\(\alpha_m\)，而是给它的所有叶节点分别赋予一个参数。<br/>
　　当设置\(J=2\)，就是采用决策桩(Decision Stump)作为基本模型。通常设置\(4\leq J\leq 8\)。</p>

<h4 id="toc_11">算法 GBDT</h4>

<p><strong>输入</strong>：训练数据集\(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，其中\(x_i\in\chi \subseteq R^{n}\)。以及weak learner 决策树模型\(\phi(x)\)；迭代次数\(M\)。<br/>
<strong>输出</strong>：\(f_M(x)\)。</p>

<p>1.初始化模型\(f_0(x)\)：<br/>
\[f_0(x)=arg\min_{\alpha}\sum_{i=1}^{N}L(y_i,\alpha)\]<br/>
2.对\(m=1,2,...M\)：<br/>
　　a.求各训练样本的伪残差：<br/>
\[r_{m,i}=-[\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)}]_{f(x)=f_{m-1}(x)}\]<br/>
　　b.在训练集\(\{(x_1,r_{m,1}),(x_2,r_{m,2}),...(x_N,r_{m,N})\}\)上训练，得到决策树模型\(\phi_m(x)\)，它有\(J\)个子区域。<br/>
　　c.对\(j=1,2,...J\)，计算<br/>
　　\[c_{m,j}=arg\min_{c}\sum_{x_i\in R_{m,j}}L(y_i, (f_{m-1}+c))\]<br/>
　　d.更新模型<br/>
\[f_m(x)=f_{m-1}(x)+\sum_{j=1}^{J}c_{m,j}I(x\in R_{m,j})\]<br/>
3.输出模型<br/>
\[f_M(x)=\sum_{m=1}^{M}\phi_m(x)\\\<br/>
=\sum_{m=1}^{M}\sum_{j=1}^{J}c_{m,j}I(x\in R_{m,j})\]</p>

<h2 id="toc_12">Reference</h2>

<blockquote>
<p>[1] 李航，统计学习方法<br/>
[2] Murphy, Machine Learning: A Probabilistic Perspective</p>
</blockquote>

<p>　　</p>

<p>　</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bagging]]></title>
    <link href="http://21stacks.top/14592424184360.html"/>
    <updated>2016-03-29T17:06:58+08:00</updated>
    <id>http://21stacks.top/14592424184360.html</id>
    <content type="html"><![CDATA[
<p>　　一种组合学习模型。通过从原始训练数据集里有放回(with replacement)地抽取数据样本，来构造新的训练集。每得到一个新的训练集就在其上训练一个模型。重复多次，得数个模型。采用求平均或Major Vote来组合这些模型，得到最终的输出模型。<br/>
　　新构造的训练集与原始训练集有着相同数量的样本，设为\(N\)。则每构造一个新训练集，原始训练集中的单个样本被抽取(即至少被抽中一次)的概率是：<br/>
　　\[p=1-(1-\frac{1}{N})^{N}\]</p>

<span id="more"></span><!-- more -->

<p>　　注意到<br/>
　　\[\lim_{N\rightarrow \infty}p=\lim_{N\rightarrow \infty}1-[(1+\frac{1}{-N})^{-N}]^{-1}=1-\frac{1}{e}\]<br/>
　　因此当\(N\)足够大时有\(p\approx 0.632\)。因此每构造一个训练集，原始训练集里有大约\(63\%\)的样本会被抽中。</p>

<h2 id="toc_0">缺陷</h2>

<p>　　对于组合学习模型而言，基本模型之间的相关性越低，组合后的效果越好。Bagging策略的基本模型之间相关性较强，因此性能不佳。</p>

<h2 id="toc_1">改进</h2>

<p>　　应设法降低训练集之间的相关性。<strong>随机森林</strong>是对Bagging的一种改进。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[随机森林]]></title>
    <link href="http://21stacks.top/14591708106411.html"/>
    <updated>2016-03-28T21:13:30+08:00</updated>
    <id>http://21stacks.top/14591708106411.html</id>
    <content type="html"><![CDATA[
<p>　　随机森林是以决策树为基本模型的Bagging策略。通过两个层次的随机性来降低基本模型的相关性，从而提高组合模型的性能。<br/>
　　1.在训练每棵树时，从训练数据集中有放回地抽取样本；<br/>
　　2.每次分裂时随机选取一个特征子集(随机子空间).</p>

<span id="more"></span><!-- more -->

<p><strong>算法：</strong><br/>
<strong>输入</strong>：训练数据集\(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，其中\(x_i\in\chi \subseteq R^{n}\)，样本含有\(n\)个属性，\(y_i\in\{-1,+1\}\)。以及基本模型\(h(x)\)(决策树)、基本模型的数量\(M\)、特征子集的大小\(sn\)。<br/>
<strong>输出</strong>：强模型\(H(x)\)。<br/>
1.对于\(m=1,2,...M\)<br/>
　　a.有放回地随机抽取训练数据集\(T_i\)；<br/>
　　b.用\(T_i\)训练\(h_i(x)\)，每次分裂时随机选取特征子集；<br/>
2.组合这M个模型，得强模型。</p>

<p><strong>Caution:</strong><br/>
1.对于分类问题，可以令特征子集的大小为\(sn=\sqrt{n}\)；对于回归问题可以令\(sn=\frac{n}{3}\)。<br/>
2.对分类问题，最终模型可以是M个模型的Major Vote；对于回归问题，可以对它们的结果求平均。<br/>
<strong>3.</strong>可以用随机森林来评估属性的重要程度。</p>

<p><strong>Feature Importance</strong><br/>
　　随机森林在建立每一棵树时都临时抽取一个训练集。因此原始训练集里的样本\(x\)可能只参与了一部分树的建立，而在建立另一些树的时候没有被使用。对于样本\(x\)，如果用那些它没有参与建立的树来处理它(分类或回归)，就会存在误差；在所有它没参与建立的树上的误差之和，就是Out-of-bag error (oob)。随机森林利用oob来评估属性的重要性，其算法描述如下。<br/>
　　<br/>
<strong>输入</strong>：训练数据集\(T\)，在\(T\)上得到的随机森林模型\(H(x)\)。<br/>
<strong>输出</strong>：属性重要性。<br/>
1.计算\(T\)中样本的平均误差\(oob\).<br/>
2.对\(j=1,2,...n\)<br/>
　　a.对\(T\)中所有样本的属性\(j\)做Permute(Shuffle)，得到临时样本集合\(T&#39;\)，求\(T&#39;\)的Out-of-bag error \(oob_j\).<br/>
　　b.属性\(j\)的重要性得分是\(S_j=oob-oob_j\)<br/>
3.输出所有属性的得分\(S\)。值越大越重要。</p>

<h2 id="toc_0">Reference</h2>

<blockquote>
<p>[1] 李航 统计学习方法<br/>
[2] Murphy, Machine Learning: A Probabilistic Perspective</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Stacked Generalization]]></title>
    <link href="http://21stacks.top/14591708106532.html"/>
    <updated>2016-03-28T21:13:30+08:00</updated>
    <id>http://21stacks.top/14591708106532.html</id>
    <content type="html"><![CDATA[
<p>　　使用多层模型，前一层的输出作为特征，当作后一层的输入。以两层模型为例。第一层使用两种分类器，生成两种meta-feature；第二层使用一个分类器，以这些meta-features为特征生成分类结果。训练集和测试集都要经历这两个层次。在第一层，对于单个分类器，可以采用k-fold来生成这个分类器对应的meta-feature。整个过程可以用以下两图表示，这里采用了2-fold。</p>

<span id="more"></span><!-- more -->

<p>　　<img src="http://7xrz9i.com1.z0.glb.clouddn.com/ensemblestackedGeneralization-Train.png" alt=""/><br/>
　　<img src="http://7xrz9i.com1.z0.glb.clouddn.com/ensemblestackedGeneralization-Test.png" alt=""/><br/>
　　C1和C2是第一层采用的分类器。<br/>
　　对<strong>训练集</strong>的操作：<br/>
　　1.划分训练集P为两个fold，PA，PB。<br/>
　　2.对于C1，生成F1：<br/>
　　　　以PA为训练集训练它，然后将C1作用于PB，生成部分meta-feature F1B；<br/>
　　　　以PB为训练集训练它，然后将C1作用于PA，生成部分meta-feature F1A；<br/>
　　　　组合以上两部分meta-feature，生成F1，a column。<br/>
　　3.对C2，生成F2：过程类似2。<br/>
　　4.组合F1和F2，生成含有两种feature（Attribute）的新数据集F，y还是原来的训练集的y。<br/>
　　对<strong>测试集</strong>：<br/>
　　同样要生成两种meta-feature。<br/>
　　1.可以用整个训练集分别训练C1和C2，然后将C1和C2作用于测试集。就像上图2那样。<br/>
　　2.也可以把上图1中得到的两个(多个)C1都作用于测试集，投票或求评价得到TF1；用同样的方法得到TF2。<br/>
　　3.组合TF1，TF2，生成TF，含两种属性。 </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logistic 回归]]></title>
    <link href="http://21stacks.top/14591708106259.html"/>
    <updated>2016-03-28T21:13:30+08:00</updated>
    <id>http://21stacks.top/14591708106259.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[线性回归]]></title>
    <link href="http://21stacks.top/14591708105958.html"/>
    <updated>2016-03-28T21:13:30+08:00</updated>
    <id>http://21stacks.top/14591708105958.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
</feed>
