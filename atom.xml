<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[]]></title>
  <link href="http://21stacks.top/atom.xml" rel="self"/>
  <link href="http://21stacks.top/"/>
  <updated>2016-04-07T16:52:02+08:00</updated>
  <id>http://21stacks.top/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[平方损失函数的背后]]></title>
    <link href="http://21stacks.top/14600116978074.html"/>
    <updated>2016-04-07T14:48:17+08:00</updated>
    <id>http://21stacks.top/14600116978074.html</id>
    <content type="html"><![CDATA[
<h3 id="toc_0">定义</h3>

<p>　　损失函数用于衡量一个模型对数据的拟合程度。最常见的损失函数莫过于平方损失函数，其形式化的表述为<br/>
\[C(\theta)=\frac{1}{2}\sum_{i=1}^{N}(y_i-h_{\theta}(x_i))^2\qquad(1)\]</p>

<span id="more"></span><!-- more -->

<p>　　其中\((x_i, y_i)\)是数据样本，\(x_i\in R^n\)；\(h_{\theta}(x)\)是以\(\theta\)为参数的一个模型，假设(hypothesis)。在前面加一个系数\(\frac{1}{2}\)的为了方便处理某些运算。平方损失函数与Sum of Square Error (SSE)、以及Residual Sum of Square (RSS)是同一个东西。本文剩余部分统一采用SSE的写法。注意还有一个常见的概念，平均平方误差(Mean Square Error, MSE)，它是SSE在数据上的平均值。MSE是一种与数据集大小无关的误差衡量，除此之外跟SSE并没有什么软区别。<br/>
\[MSE=\frac{1}{2N}\sum_{i=1}^{N}(y_i-h_{\theta}(x_i))^2\qquad(2)\]</p>

<h3 id="toc_1">直观含义</h3>

<p>　　从式(1)可以清楚地看到，SSE直观地表示了模型\(h_{\theta}(x)\)对\(y\)的拟合程度的好坏。\(SSE\geq 0\)，且拟合程度越好SSE越小，一个完美拟合的模型会使SSE为0。在对数据集建立分类或回归模型时，我们追求的目标是尽可能地找到一个模型，使得<br/>
\[y=h_{\theta}(x)\qquad(3)\]<br/>
　　很多算法对模型的学习策略都是通过极小化SSE来实现的。不幸的是，我们总不能完美找到一个这样的模型。不能的意思有两层。一是说能力不够，受制于所选模型特性等因素，并不总能得到一个完美的拟合，例如无法用感知机模型对线性不可分的数据完美地划分。 二是说不应该，在训练数据集上完美拟合的模型通常是过拟合的泛化能力不好的模型。后者的主要原因是训练数据中存在的噪声，以及模型自身的缺陷。因此通常情况下，由模型得出的预测值与\(y\)之间的关系是这样的<br/>
\[y=h_{\theta}(x)+\epsilon\qquad(4)\]<br/>
　　\(\epsilon\)表示\(\hat{y}=h_{\theta}(x)\)对\(y\)的误差。</p>

<h3 id="toc_2">从参数估计的角度来看</h3>

<p>　　为什么通过极小化SSE得到的模型是好的？除了直观感觉，我们也可以从参数估计的角度做一些推理。这里我们关注的是式(4)中的误差<br/>
\[\epsilon=y-h_{\theta}(x)\qquad(5)\]<br/>
　　对于一组数据\(\{(x_1,y_1),(x_2,y_2),...,(x_i,y_i),...,(x_N,y_N)\}\)，可以得到一组误差值\(\{\epsilon_1,\epsilon_2,...,\epsilon_i,...,\epsilon_N \}\)。通常认为这个误差集里的数据是源于总体分布\(f(x|\theta)\)的抽样，它们独立同分布。因此所有\(\epsilon\)的联合概率密度为<br/>
\[f(\epsilon_1,...,\epsilon_N|\theta)=f(\epsilon_1|\theta)f(\epsilon_2|\theta)\cdot\cdot\cdot f(\epsilon_N|\theta)\qquad(6)\]<br/>
　　记\(L(\epsilon_1,...,\epsilon_N|\theta)=f(\epsilon_1,...,\epsilon_N|\theta)\)为似然函数，\(\theta\)是待估计的参数。若\(L(\epsilon_1,...,\epsilon_N|\theta_1)&gt;L(\epsilon_1,...,\epsilon_N|\theta_2)\)，我们说当已知\(\{\epsilon_1,...,\epsilon_N\}\)时，待估计参数\(\theta\)是\(\theta_1\)的可能性大于\(\theta_2\)。因此我们有了一个优化目标：要寻求一个\(\theta&#39;\)，使\(L\)尽可能大。<br/>
进一步假设\(\epsilon_i\)符合一个均值为0的高斯分布(Or, what else can it be ?)；其方差为某\(\sigma^2\)。即\(\epsilon\)的分布的概率密度函数为<br/>
\[f(\epsilon|\theta)=(\frac{1}{2\pi\sigma^2})^{\frac{1}{2}}exp(-\frac{\epsilon^2}{2\sigma^2})\qquad(7)\]<br/>
于是，似然函数可写成<br/>
\[L(\theta)=\prod_{i=1}^{N}(\frac{1}{2\pi\sigma^2})^{\frac{1}{2}}exp(-\frac{\epsilon_i^2}{2\sigma^2})\qquad(8)\]<br/>
为了方便处理，对式(8)左右两边去自然对数，\(g(z)=lnz\)是\(z\)的单调递增函数，因此优化目标不变。整理得<br/>
\[lnL(\theta)=-\frac{1}{2\sigma^2}\sum_{i=1}^{N}\epsilon^2-\frac{N}{2}ln(2\pi\sigma^2)\qquad(9)\]<br/>
将式(5)代入(9)，得<br/>
\[lnL(\theta)=-\frac{1}{2\sigma^2}\sum_{i=1}^{N}(y_i-h_{\theta(x_i)})^2-\frac{N}{2}ln(2\pi\sigma^2)\qquad(10)\]<br/>
式(10)中，等号右边的第二项与\(\theta\)无关，因此要极大化\(lnL(\theta)\)就是要极大化等号右边第一项。由于\(\sigma^2\)是某个正实数，因此我们的优化目标就相当于求<br/>
\[\theta&#39;=arg\min_{\theta}\frac{1}{2}\sum_{i=1}^{N}(y_i-h_{\theta}(x_i))^2\qquad(11)\]<br/>
式(11)正是极小化SSE的方法所寻求的。对于线性回归模型，\(h_{\theta}(x)=\theta^Tx\)，代入(11)得<br/>
\[\theta&#39;=arg\min_{\theta}\frac{1}{2}\sum_{i=1}^{N}(y_i-\theta^Tx_i)^2\qquad(12)\]<br/>
求解(12)式既可以采用求导函数零点的方式，也可以使用迭代式的解法如<a href="http://acesmg.github.io/14598347945676.html">梯度下降法</a>。</p>

<h3 id="toc_3">Reference</h3>

<blockquote>
<p>陈希孺，概率论与数理统计<br/>
Wikipedia: <a href="https://en.wikipedia.org/wiki/Maximum_likelihood">Maximum Likelihood</a><br/>
Murphy, Machine Learning: A Probabilistic Perspective.</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[梯度下降]]></title>
    <link href="http://21stacks.top/14598347945676.html"/>
    <updated>2016-04-05T13:39:54+08:00</updated>
    <id>http://21stacks.top/14598347945676.html</id>
    <content type="html"><![CDATA[
<p>　　梯度下降算法是一种常见的无约束优化问题求解算法。其主要特点有：<br/>
　　1.迭代式，逐步逼近；<br/>
　　2.只能在待优化函数的可导邻域内寻优；<br/>
　　3.沿梯度的反方向搜索；<br/>
　　3.实现相对简单。<br/>
　　设优化目标为<br/>
\[\min_{x}F(x)\qquad (1)\]<br/>
　　\(F(x)\)是\(R^{n}\)上一阶可导函数。现在要求一个\(x\in R^{n}\)，使\(F(x)\)达到极小值。</p>

<span id="more"></span><!-- more -->

<p>　　梯度下降算法基于这样一个事实：</p>

<blockquote>
<p>如果函数\(F(x)\)在点\(x=x_m\)的一个邻域内可微，则当\(x\)沿着这个点的梯度的反方向变化时，\(F(x)\)下降的速度最快。</p>
</blockquote>

<p>　　也就是说，\(x\)应按下式变化：<br/>
\[x_{m+1}=x_m-\gamma \triangledown F(x_m)\qquad (2)\]<br/>
　　其中\(\triangledown F(x_m)\)是\(F(x)\)在\(x_m\)处的梯度；\(\gamma\)是一个较小的系数，控制着\(x\)更新的步长。当\(\gamma\)足够小，有\(F(x_{m+1})\leq F(x_m)\)。梯度下降算法通过迭代的方式逐渐减小\(F(x)\)的值，在每一步迭代中要完成的工作就是求梯度值，以及步长\(\gamma\)。算法的描述如下。</p>

<h4 id="toc_0">算法 Gradient Descent</h4>

<p><strong>输入</strong>：目标函数\(F(x)\)，最大迭代次数\(M\)。<br/>
<strong>输出</strong>：\(F(x)\)的极小值点\(x&#39;\)。</p>

<p>1.初始化\(x_0\)，令其为\(R^{n}\)上的某个点。<br/>
2.对\(m=1,2,...,M\)<br/>
　　a.求梯度\(\triangledown F(x_m)\)；<br/>
　　b.求步长\(\gamma\)；<br/>
　　c.更新\(x\)，令\(x_{m+1}=x_m-\gamma\triangledown\)。<br/>
3.输出\(x&#39;=x^{M}\)。</p>

<p>　　也可以设定一个较小的值\(\varepsilon\)，当\(x\)或\(F(x)\)的更新小于它时，提前结束算法。</p>

<h4 id="toc_1">步长</h4>

<p>　　以上算法中没有对步骤2.b求步长\(\gamma\)的表述。对步长的求解有很多方法，可以直接预设其为一个很小的正实数、可以以\(\gamma\)为自变量对\(F(x)\)求导以得到一个确切的值、也可以采用线性搜索的方式求一个适当的值。通常，线性搜索是更合理的方式，其计算量不大，找到的值足够好。</p>

<h4 id="toc_2">Backtracking Line Search (BLS)</h4>

<p>　　BLS是一种迭代式的线性搜索方法。令\(\gamma\)为一个较大的值，然后通过一个系数\(\tau \in (0,1)\)来逐步减小\(\gamma\)。</p>

<h5 id="toc_3">算法 BLS</h5>

<p><strong>输入</strong>：\(F(x)\)、\(x_m\)，\(\triangledown F(x_m)=p\)，\(\tau \in (0,1)\)，一个控制参数\(c\in (0,1)\)。<br/>
<strong>输出</strong>：\(\gamma&#39;\)。</p>

<p>1.令\(\gamma\)为一个较大值；\(m= -\parallel p \parallel &lt;0\)；<br/>
2.循环，令<br/>
\[\gamma=\tau\gamma\]<br/>
　直到\(F(x+\gamma m)\leq F(x)+\gamma c m\)。<br/>
3.输出\(\gamma&#39;=\gamma\)。</p>

<h4 id="toc_4">Why Gradient Descent ?</h4>

<p>　　要求一个函数的极小值，最直观的想法莫过于求目标函数导函数的零点了。为什么我们还需要像梯度下降这样的迭代式算法呢？<br/>
　　梯度下降算法最常用的场景是极小化机器学习模型的损失函数。对于大多数非线性模型而言，损失函数的优化不存在封闭解，因此不能用求导函数零点的方法来解。对于线性模型(待优化参数的线性函数)，存在封闭解，但求封闭解的计算复杂度较高，在实践上通常不易计算。<br/>
　　例如对于我们熟知的线性回归模型，其平方损失函数可以定义为<br/>
\[J(\theta)=\frac{1}{2}\sum_{i=1}^{N}(x_i\theta-y_i)^2\]<br/>
　　其中\(x_i\)是第\(i\)个训练样本，是一个\(M\)行向量；\(\Theta\)是回归模型的参数，是一个\(M\)维列向量。所以上式也可以写成<br/>
\[J=\frac{1}{2}\sum_{i=1}^{N}[\sum_{j=1}^{M}x_{ij}\theta_j]^2\]<br/>
优化目标为求<br/>
\[\theta&#39;=arg\min_{\theta}J(\theta)\]<br/>
对损失函数求导，让导数为0，对\(j=1,2,...M\)有，<br/>
\[\frac{\partial J(\theta)}{\partial \theta_j}=\sum_{i=1}^{N}x_{ij} *(\sum_{k=1}^{M}x_{ik}\theta_k-y_i)=0\]<br/>
整合成矩阵形式有：<br/>
\[\frac{\partial J(\theta)}{\partial \theta}=X^{T}X\theta-X^{T}Y=0\]<br/>
于是得到解<br/>
\[\theta&#39;=(X^{T}X)^{-1}X^{T}Y\]<br/>
　　上式表明，为了求损失函数的极小值点，要求矩阵\(X^{T}X\)的逆矩阵。对于一个\(n\times n\)的矩阵，求逆矩阵运算的时间复杂度为\(O(n^3)\)，当\(n\)较大时，耗时很久。</p>

<h4 id="toc_5">Wrap it up</h4>

<p>　　如果待优化的目标函数是凸函数，则梯度下降算法可以得到全局最优解(Global Optimum)。否则，求得的大多是局部最优。步长和初始点的选择都会影响梯度下降算法的寻优结果。相比于牛顿法，梯度下降的收敛需要更多的迭代次数，但计算更简单。相比于群智能算法，梯度下降算法寻优能力较弱，且只适用于可微目标函数。</p>

<h4 id="toc_6">Reference</h4>

<blockquote>
<p>李航 统计学习方法<br/>
<a href="https://en.wikipedia.org/wiki/Gradient_descent">Wikipedia: Gradient Descent</a></p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Boosting]]></title>
    <link href="http://21stacks.top/14592400407522.html"/>
    <updated>2016-03-29T16:27:20+08:00</updated>
    <id>http://21stacks.top/14592400407522.html</id>
    <content type="html"><![CDATA[
<p>　　Boosting是一种Adaptive Basis-function Model (ABM)。ABM模型可以用式(1)高度概括：<br/>
\[f(x)=w_0+\sum_{m=1}^{M} w_m \phi_m(x) \qquad(1)\]<br/>
　　这里的\(\phi_m(x)\)是从数据中学习而来的第\(m\)个基本模型(基函数)。ABM通过多个模型的线性组合来得到<strong>非线性</strong>的模型。事实上，决策树就是一种ABM。一棵具有\(M\)个叶子节点的决策树可以表示为：<br/>
\[T(x)=\sum_{m=1}^{M}w_mI(x\in R_m)\qquad (2)\]<br/>
　　\(R_m\)是决策树的第\(m\)个叶节点；\(w_m\)表示第\(m\)个叶节点的标示值(输出)；当样本x属于第\(m\)个叶节点时，函数\(I(x \in R_m)\)输出1，否则输出0。<br/>
　　Boosting是除了决策树以外的另一种常见的ABM模型。Boosting中的基本模型也叫做weak learner。被使用最多的基本模型是CART。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">前向分步算法</h2>

<p>　　为了得到一个ABM模型，需要求数个基函数，以及它们对应的系数。Boosting方法的核心是前向分步算法。前向分步的意思就是，逐步往前构建，且不回头来调整。若最终要达成的模型含有\(M\)个基函数，则前向分步算法要经过\(M\)次迭代。在第\(m\)次(\(0&lt;m\leq M\))迭代时通过以下公式求得\(f_m\)：<br/>
\[f_{m}(x)=f_{m-1}(x)+\alpha_m\phi_m(x) \qquad(3)\]<br/>
而最终的模型就是\(f(x)=f_M(x)\)。这里用\(\alpha_m\)代替了式(1)中的\(w_m\)。<br/>
　　在求\(f_m\)时，我们已经得到了\(f_{m-1}\)。因此只要得到第\(m\)个基函数\(\phi_m(x)\)及其系数\(\alpha_m\)，就可以通过(3)式构造出\(f_m\)。Boosting在第\(m\)次迭代中通过极小化损失函数来求\(f_m(x)\)。其优化目标可用下式表示：<br/>
\[\min_{f_m}=\sum_{i=1}^{N}L(y_i,f_m(x_i))\qquad (4)\]<br/>
　　上式中，\(L\)是损失函数，\(N\)是训练集的大小。具体的Boosting算法有很多种，它们采用了各种不同的损失函数。<br/>
　　把(3)带入(4)式，我们的优化目标可以写成：<br/>
\[(\phi_m,\alpha_m)=\min_{\phi,\alpha}\sum_{i=1}^{N}L(y_i,f_{m-1}(x)+\alpha\phi(x)) \qquad(5)\]<br/>
　　通过以上表述可以知道，Boosting是一种贪心策略，在迭代的过程中逐步逼近优化目标，求得模型的不是Global Optimum。</p>

<h2 id="toc_1">AdaBoost</h2>

<p>　　AdaBoost(Adaptive Boost)是最常见的一种Boosting算法。它被认为是最好的out-of-the-box(咋翻译？)分类算法。AdaBoost为每个训练样本赋予了不同的权值，表示它们的重要性(分类的难易程度)。在训练过程中，随着迭代的进行，难以分类的样本权值会变得更高，使模型逐步倾向这些样本。</p>

<h4 id="toc_2">推理</h4>

<p>　　一下讨论基于二分类问题，令\(y_i\in\{-1,1\}\)。<br/>
　　AdaBoost采用的损失函数是指数损失函数。在前向分步算法的第\(m\)步，优化的目标函数就是式(6)：<br/>
\[L_m(\phi)=\sum_{i=1}^{N} exp[-y_i(f_{m-1}(x_i)+\alpha\phi(x_i))]\qquad(6)\]<br/>
　　下面要描述的是如何通过优化(6)来求\(\alpha\)和\(\phi(x)\)。<br/>
　　首先，令<br/>
\[w_{m,i}=exp[-y_if_{m-1}(x_i)]\qquad(7)\]<br/>
\(w_{m,i}\)表示开始第\(m\)次迭代时，第\(i\)个训练样本的权重。于是(6)可以表示为：<br/>
\[L_m(\phi)=\sum_{i=1}^{N}w_{m,i}exp(-\alpha y_i \phi(x_i))\qquad(8)\]<br/>
此时如果把训练样本输入到基本模型\(\phi(x)\)，则有的样本会被正确分类，另一些则被错误分类。在上式中把这两类样本分开来，可以改写成：<br/>
\[L_m=e^{-\alpha}\sum_{y_i=\phi(x_i)}^{}w_{m,i}+e^{\alpha}\sum_{y_i\neq \phi(x_i)}^{}w_{m,i}\\\<br/>
=(e^{\alpha}-e^{-\alpha})\sum_{i=1}^{N}w_{m,i}I(y_i\neq \phi(x_i))+e^{-\alpha}\sum_{i=1}^{N}w_{m,i}<br/>
\qquad(9)\]<br/>
因为\(\alpha\geq 0\)，所以\((e^{\alpha}-e^{-\alpha})\geq 0\)。于是可得，能使\(L_m\)极小化的\(\phi_m\)就如<strong>(10)</strong>所示：<br/>
\[\phi_m(x)=arg\min_{\phi}\sum_{i=1}^{N}w_{m,i}I(y_i \neq \phi(x_i))\qquad(10)\]<br/>
上式中，\(\sum_{i=1}^{N}w_{m,i}I(y_i\neq\phi_m(x))\)可以定义为\(\phi_M(x)\)在训练集上的加权分类误差\(e_m\)。<br/>
\[e_m=\sum_{i=1}^{N}w_{m,i}I(y_i\neq\phi_m(x))\qquad(11)\]<br/>
　　接着来求\(\phi_m(x)\)的系数\(\alpha_m\)。在式(9)上对\(\alpha\)求导，令导数为0：<br/>
\[\frac{d L_m}{d \alpha}=e^{\alpha}\sum_{i=1}^{N}w_{m,i}I(y_i\neq\phi_m(x))-e^{-\alpha}\sum_{i=1}^{N}w_{m,i}I(y_i=\phi_m(x_i))=0\qquad(12)\]<br/>
化简可得：<br/>
\[\alpha=\frac{1}{2}ln{\frac{\sum_{i=1}^{N}w_{m,i}I(y_i=\phi_m(x_i))}{\sum_{i=1}^{N}w_{m,i}I(y_i\neq\phi_m(x_i))}}\qquad(13)\]<br/>
式(13)中，分子是所有被\(\phi_m(x)\)正确分类的样本的权值之和，分母是所有被\(\phi_m(x)\)误分类的样本的权值之和，因此有：<br/>
\[\alpha_m=\frac{1}{2}ln{\frac{1-e_m}{e_m}}\qquad(14)\]<br/>
　　权值\(\alpha_m\)表示模型\(\phi_m(x)\)在最终的组合模型中的话语权大小。当\(e_m&lt;0.5\)时，\(\alpha_m&gt;0\)，且\(\alpha_m\)随着\(e_m\)的减小而增大，即误差越小的模型越权威。<br/>
　　到此我们找到了极小化\(L_m\)的weak learner \(\phi_m(x)\)和它的权重系数\(\alpha_m\)。顺势可以使用式(3)求得在第\(m\)次迭代时的\(f_m(x)\)。<br/>
　　前面我们令\(w_{m,i}=exp[-y_i f_{m-1}(x_i)]\)，即每一次都使用上一次迭代得到的\(f_{m-1}(x)\)来更新训练集样本的权值。若已求得\(f_{m}(x)\)，则在第\({m+1}\)次迭代求\(w_{m+1,i}\)的方法如下：<br/>
\[w_{m+1,i}=exp[-y_i f_{m}(x_i)]\\<br/>
=exp[-y_i(f_{m-1}(x_i) +\alpha_m\phi_m(x_i)  )]\\<br/>
=w_{m,i} * e^{-y_i \alpha_m \phi_m(x_i)}\qquad\quad(15)\]<br/>
　　上式的效果就是让那些在\(\phi_m(x)\)上被正确分类的样本对应的权值变小，使错误分类的样本的权值变大。这就使得后续的学习偏重于处理较难分类的样本。<br/>
　　为了让\(w_{m,i}\)成为一种概率分布，还要进一步正规化：<br/>
\[w_{m+1,i}=\frac{w_{m,i}exp[-y_i\alpha_m\phi_m(x_i)]}{Z_m}\qquad(16)\\<br/>
Z_m=\sum_{i=1}^{N}w_{m,i}exp[-y_i\alpha_m\phi_m(x_i)]\qquad(17)<br/>
\]<br/>
　　在第一次迭代时要用到\(f_0(x)\)，因此预先定义\(f_0(x)=0\)(一个常数)。于是有\(w_{1,i}=exp[-y_if_0(x_i)]=1\)，对\(i=1,2,...N\)。正规化后有\(w_{1,i}=\frac{1}{N}\)。下一部分总结性地描述了AdaBoost算法。<br/>
　　</p>

<h4 id="toc_3">算法 Adaboost</h4>

<p><strong>输入</strong>：训练数据集\(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，其中\(x_i\in\chi \subseteq R^{n}\)，\(y_i\in\{-1,+1\}\)。以及弱基本模型\(\phi(x)\)；迭代次数\(M\)。<br/>
<strong>输出</strong>：强分类器\(\Phi(x)\)。</p>

<p>1.初始化训练样本的权值分布：<br/>
\[D_1=(w_{11},...,w_{1i},...w_{1N}),\quad w_{1i}=\frac{1}{N},\quad i=1,2,...N\]<br/>
2.对\(m=1,2,...M\)<br/>
　　a.使用训练数据集和它的权值分布\(D_m\)训练学习模型，得到弱基本模型\(\phi_m(x)\)，此模型满足式(10)。<br/>
　　b.根据式(11)计算\(\phi_m(x)\)在训练数据集上的带权误差<br/>
　　\[e_m=\sum_{i=1}^N w_{m,i}I(\phi_m(x_i)\neq y_i)\]<br/>
　　c.根据式(14)计算\(\phi_m(x)\)的权重系数<br/>
　　\[\alpha_m=\frac{1}{2}ln\frac{1-e_m}{e_m}\]<br/>
　　d.根据式(16)和(17)更新训练数据集的权值分布<br/>
\[D_{m+1}=(w_{m+1,1},...,w_{m+1,i},...w_{m+1,N})\\\<br/>
w_{m+1,i}=\frac{w_{m,i} exp(-y_i \alpha_m \phi_m(x_i))}{Z_m}\\\<br/>
Z_m=\sum_{i=1}^{N} w_{m,i}exp(-y_i \alpha_m h_m(x_i))\]<br/>
3.组合得到最终分类器<br/>
\[\Phi(x)=sign(f_M(x))=sign(\sum_{m=1}^{M}\alpha_m \phi_m(x))\]</p>

<h4 id="toc_4">局限性</h4>

<p>　　AdaBoost容易偏向于难以分类的样本，因此对Outlier很敏感，容易过拟合。</p>

<h2 id="toc_5">其他Boosting算法</h2>

<h4 id="toc_6">L2Boosting</h4>

<p>　　在Boosting的前向分步算法中，若采用平方误差损失函数，就得到了L2Boosting模型。在L2Boosting模型中，weak learner的权重系数通常都设为1。因此在前向分步算法的第\(m\)次迭代时要优化的目标就是求：<br/>
\[\phi_m=arg\min_{\phi}\sum_{i=1}^{N}L(y_i,f_{m-1}(x_i)+\phi(x_i))\] <br/>
这里\(L(y,f_{m-1}(x)+\phi(x))=[y-f_{m-1}(x)-\phi(x)]^2\)。也就是说，要寻求一个\(\phi_m\)，使得\(\phi_m(x)\)尽可能地靠近(拟合)\(y-f_{m-1}(x)\)。令\(r=y-f_{m-1}(x)\)为当前模型(\(f_{m-1}(x)\))拟合训练样本的<strong>残差</strong>。在第\(m\)次迭代时，样本\(i\)对应的残差为：<br/>
\[r_{m,i}=y_i-f_{m-1}(x_i)\]<br/>
　　L2Boosting算法的迭代过程，就是通过拟合残差来学习新的weak learner，并把这些weak learner线性组合以得到强模型。</p>

<h2 id="toc_7">梯度提升Gradient Boosting</h2>

<p>　　Boosting算法可以采用各种不同的损失函数。这些算法可以归结为一种统一的形式，即梯度提升算法。梯度提升算法可以使用任意的合理的<strong>可微</strong>损失函数。对Boosting模型，我们在每一次迭代时都是求\(\phi_m(x)\)和\(\alpha_m\)，尽可能地使<br/>
　　\[f_{m+1}(x)=f_m(x)+\alpha_m\phi_m(x)\rightarrow y\]<br/>
即尽可能地让\(\alpha_m(x_i)\phi_m(x_i)\rightarrow y_i-f_m(x_i)\)。<br/>
上式右边正是残差。如果采用损失函数：<br/>
\[L=\frac{1}{2}\sum_{i=1}^{N}(y_i-f_m(x_i))^2\]<br/>
则此残差就是损失函数的负梯度值：<br/>
\[-\frac{\partial L}{\partial f_m(x_i)}=y-f_m(x_i)\]<br/>
　　对于一般化的损失函数，梯度提升算法采用损失函数负梯度值作为残差的近似值(<strong>伪残差</strong>)。在训练样本(输入向量)及其伪残差形成的数据集上训练新的weak learner。<br/>
　　像其他的Boosting算法一样，梯度提升算法也采用前向分步算法。在第\(m\)次迭代时，要求weak learner \(\phi_m(x)\)以及它对应的权重系数\(\alpha_m\)，以极小化损失函数为目标。梯度提升通过拟合伪残差来得到\(\phi_m(x)\)，然后求解一维的(以\(\alpha_m\)为自变量)优化问题得到\(\alpha_m\)。<br/>
　　</p>

<h4 id="toc_8">算法 Gradient Boosting</h4>

<p><strong>输入</strong>：训练数据集\(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，其中\(x_i\in\chi \subseteq R^{n}\)。以及weak learner模型\(\phi(x)\)；迭代次数\(M\)。<br/>
<strong>输出</strong>：强模型\(f_M(x)\)。</p>

<p>1.初始化模型\(f_0(x)\)(一个常数)：<br/>
\[f_0(x)=arg\min_{\alpha}\sum_{i=1}^{N}L(y_i,\alpha)\]<br/>
2.对\(m=1,2,...M\)：<br/>
　　a.求各训练样本的伪残差：<br/>
\[r_{m,i}=-[\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)}]_{f(x)=f_{m-1}(x)}\]<br/>
　　b.在训练集\(\{(x_1,r_{m,1}),(x_2,r_{m,2}),...(x_N,r_{m,N})\}\)上训练基本模型，得到\(\phi_m(x)\)。<br/>
　　c.解一维优化问题，求\(\alpha_m\)<br/>
\[\alpha_m=arg\min_{\alpha}\sum_{i=1}^{N}L(y_i,f_{m-1}(x_i)+\alpha\phi_m(x_i))\]<br/>
　　d.更新模型<br/>
\[f_m(x)=f_{m-1}(x)+\alpha_m\phi_m(x)\]<br/>
3.输出 \(f_M(x)\)。</p>

<h4 id="toc_9">正则化</h4>

<p>　　为了提高模型的泛化能力，可以采用多种正则化策略。<br/>
　　1.限制迭代次数\(M\)。迭代次数决定了基本模型的数量。较大的\(M\)能减小训练误差，但容易过拟合。可以单独采用一个验证集，在迭代过程中评估泛化误差。<br/>
　　2.Shrinkage。给新学得的模型加一个较小的系数，以限制其对最终模型的影响：<br/>
\[f_m(x)=f_{m-1}(x)+ v\alpha_m\phi_m(x)\qquad 0&lt;v\leq 1\]<br/>
这个\(v\)也就是learning rate。较小的\(v\)会减慢算法的收敛速度，但能得到更好的模型。<br/>
　　2.随机梯度提升。在迭代过程中每次都从原始训练集选择一个子集。通常抽取原数据集一半大小的子集。<br/>
　　3.当采用决策树作为基本模型时，可以限制叶节点内的样本数。若节点样本数小于一定值，则不再划分。</p>

<h2 id="toc_10">GBDT</h2>

<p>　　Gradient Boosting如果采用决策树作为基本模型，就得到了Gradient Boosting Decision Tree(GBDT)。也就是说在梯度提升算法的迭代过程中，每次要找的基本模型就是一棵树。树的叶节点们把输入空间划分成多个子区域，并对各子区域分别估计响应值(如对回归问题求落入该区域样本y值的平均，对分类问题采取多数投票)。设\(\phi_m(x)\)是一棵决策树，它把输入空间划分成\(J\)个区域，则\(\phi_m(x)\)可以表示为<br/>
\[\phi_m(x)=\sum_{j=1}^{J}c_{m,j}I(x\in R_{m,j})\]<br/>
这里\(R_{m,j}\)表示树\(\phi_m(x)\)的第\(j\)个叶节点(输入空间子区域)，\(c_{m,j}\)是其对应的响应值。<br/>
　　这也就是说，GBDT对梯度提升算法做了改进，不再是给模型\(\phi_m(x)\)一个参数\(\alpha_m\)，而是给它的所有叶节点分别赋予一个参数。<br/>
　　当设置\(J=2\)，就是采用决策桩(Decision Stump)作为基本模型。通常设置\(4\leq J\leq 8\)。</p>

<h4 id="toc_11">算法 GBDT</h4>

<p><strong>输入</strong>：训练数据集\(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，其中\(x_i\in\chi \subseteq R^{n}\)。以及weak learner 决策树模型\(\phi(x)\)；迭代次数\(M\)。<br/>
<strong>输出</strong>：\(f_M(x)\)。</p>

<p>1.初始化模型\(f_0(x)\)：<br/>
\[f_0(x)=arg\min_{\alpha}\sum_{i=1}^{N}L(y_i,\alpha)\]<br/>
2.对\(m=1,2,...M\)：<br/>
　　a.求各训练样本的伪残差：<br/>
\[r_{m,i}=-[\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)}]_{f(x)=f_{m-1}(x)}\]<br/>
　　b.在训练集\(\{(x_1,r_{m,1}),(x_2,r_{m,2}),...(x_N,r_{m,N})\}\)上训练，得到决策树模型\(\phi_m(x)\)，它有\(J\)个子区域。<br/>
　　c.对\(j=1,2,...J\)，计算<br/>
　　\[c_{m,j}=arg\min_{c}\sum_{x_i\in R_{m,j}}L(y_i, (f_{m-1}+c))\]<br/>
　　d.更新模型<br/>
\[f_m(x)=f_{m-1}(x)+\sum_{j=1}^{J}c_{m,j}I(x\in R_{m,j})\]<br/>
3.输出模型<br/>
\[f_M(x)=\sum_{m=1}^{M}\phi_m(x)\\\<br/>
=\sum_{m=1}^{M}\sum_{j=1}^{J}c_{m,j}I(x\in R_{m,j})\]</p>

<h2 id="toc_12">Reference</h2>

<blockquote>
<p>统计学习方法<br/>
Machine Learning: A Probabilistic Perspective</p>
</blockquote>

<p>　　</p>

<p>　</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bagging]]></title>
    <link href="http://21stacks.top/14592424184360.html"/>
    <updated>2016-03-29T17:06:58+08:00</updated>
    <id>http://21stacks.top/14592424184360.html</id>
    <content type="html"><![CDATA[
<p>　　一种组合学习模型。通过从原始训练数据集里有放回(with replacement)地抽取数据样本，来构造新的训练集。每得到一个新的训练集就在其上训练一个模型。重复多次，得数个模型。采用求平均或Major Vote来组合这些模型，得到最终的输出模型。<br/>
　　新构造的训练集与原始训练集有着相同数量的样本，设为\(N\)。则每构造一个新训练集，原始训练集中的单个样本被抽取(即至少被抽中一次)的概率是：<br/>
　　\[p=1-(1-\frac{1}{N})^{N}\]</p>

<span id="more"></span><!-- more -->

<p>　　注意到<br/>
　　\[\lim_{N\rightarrow \infty}p=\lim_{N\rightarrow \infty}1-[(1+\frac{1}{-N})^{-N}]^{-1}=1-\frac{1}{e}\]<br/>
　　因此当\(N\)足够大时有\(p\approx 0.632\)。因此每构造一个训练集，原始训练集里有大约\(63\%\)的样本会被抽中。</p>

<h2 id="toc_0">缺陷</h2>

<p>　　对于组合学习模型而言，基本模型之间的相关性越低，组合后的效果越好。Bagging策略的基本模型之间相关性较强，因此性能不佳。</p>

<h2 id="toc_1">改进</h2>

<p>　　应设法降低训练集之间的相关性。<strong>随机森林</strong>是对Bagging的一种改进。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[随机森林]]></title>
    <link href="http://21stacks.top/14591708106411.html"/>
    <updated>2016-03-28T21:13:30+08:00</updated>
    <id>http://21stacks.top/14591708106411.html</id>
    <content type="html"><![CDATA[
<p>　　随机森林是以决策树为基本模型的Bagging策略。通过两个层次的随机性来降低基本模型的相关性，从而提高组合模型的性能。<br/>
　　1.在训练每棵树时，从训练数据集中有放回地抽取样本；<br/>
　　2.每次分裂时随机选取一个特征子集(随机子空间).</p>

<span id="more"></span><!-- more -->

<p><strong>算法：</strong><br/>
输入：训练数据集\(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，其中\(x_i\in\chi \subseteq R^{n}\)，样本含有\(n\)个属性，\(y_i\in\{-1,+1\}\)。以及基本模型\(h(x)\)(决策树)、基本模型的数量\(M\)、特征子集的大小\(sn\)。<br/>
输出：强模型\(H(x)\)。<br/>
1.对于\(m=1,2,...M\)<br/>
　　a.有放回地随机抽取训练数据集\(T_i\)；<br/>
　　b.用\(T_i\)训练\(h_i(x)\)，每次分裂时随机选取特征子集；<br/>
2.组合这M个模型，得强模型。</p>

<p><strong>Caution:</strong><br/>
1.对于分类问题，可以令特征子集的大小为\(sn=\sqrt{n}\)；对于回归问题可以令\(sn=\frac{n}{3}\)。<br/>
2.对分类问题，最终模型可以是M个模型的Major Vote；对于回归问题，可以对它们的结果求平均。<br/>
<strong>3.</strong>可以用随机森林来评估属性的重要程度。</p>

<p><strong>Feature Importance</strong><br/>
　　随机森林在建立每一棵树时都临时抽取一个训练集。因此原始训练集里的样本\(x\)可能只参与了一部分树的建立，而在建立另一些树的时候没有被使用。对于样本\(x\)，如果用那些它没有参与建立的树来处理它(分类或回归)，就会存在误差；在所有它没参与建立的树上的误差之和，就是Out-of-bag error (oob)。随机森林利用oob来评估属性的重要性，其算法描述如下。<br/>
　　<br/>
<strong>输入</strong>：训练数据集\(T\)，在\(T\)上得到的随机森林模型\(H(x)\)。<br/>
<strong>输出</strong>：属性重要性。<br/>
1.计算\(T\)中样本的平均误差\(oob\).<br/>
2.对\(j=1,2,...n\)<br/>
　　a.对\(T\)中所有样本的属性\(j\)做Permute(Shuffle)，得到临时样本集合\(T&#39;\)，求\(T&#39;\)的Out-of-bag error \(oob_j\).<br/>
　　b.属性\(j\)的重要性得分是\(S_j=oob-oob_j\)<br/>
3.输出所有属性的得分\(S\)。值越大越重要。</p>

<h2 id="toc_0">Reference</h2>

<blockquote>
<p>统计学习方法<br/>
Machine Learning: A Probabilistic Perspective</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Stacked Generalization]]></title>
    <link href="http://21stacks.top/14591708106532.html"/>
    <updated>2016-03-28T21:13:30+08:00</updated>
    <id>http://21stacks.top/14591708106532.html</id>
    <content type="html"><![CDATA[
<p>　　使用多层模型，前一层的输出作为特征，当作后一层的输入。以两层模型为例。第一层使用两种分类器，生成两种meta-feature；第二层使用一个分类器，以这些meta-features为特征生成分类结果。训练集和测试集都要经历这两个层次。在第一层，对于单个分类器，可以采用k-fold来生成这个分类器对应的meta-feature。整个过程可以用以下两图表示，这里采用了2-fold。</p>

<span id="more"></span><!-- more -->

<p>　　<img src="http://7xrz9i.com1.z0.glb.clouddn.com/ensemblestackedGeneralization-Train.png" alt=""/><br/>
　　<img src="http://7xrz9i.com1.z0.glb.clouddn.com/ensemblestackedGeneralization-Test.png" alt=""/><br/>
　　C1和C2是第一层采用的分类器。<br/>
　　对<strong>训练集</strong>的操作：<br/>
　　1.划分训练集P为两个fold，PA，PB。<br/>
　　2.对于C1，生成F1：<br/>
　　　　以PA为训练集训练它，然后将C1作用于PB，生成部分meta-feature F1B；<br/>
　　　　以PB为训练集训练它，然后将C1作用于PA，生成部分meta-feature F1A；<br/>
　　　　组合以上两部分meta-feature，生成F1，a column。<br/>
　　3.对C2，生成F2：过程类似2。<br/>
　　4.组合F1和F2，生成含有两种feature（Attribute）的新数据集F，y还是原来的训练集的y。<br/>
　　对<strong>测试集</strong>：<br/>
　　同样要生成两种meta-feature。<br/>
　　1.可以用整个训练集分别训练C1和C2，然后将C1和C2作用于测试集。就像上图2那样。<br/>
　　2.也可以把上图1中得到的两个(多个)C1都作用于测试集，投票或求评价得到TF1；用同样的方法得到TF2。<br/>
　　3.组合TF1，TF2，生成TF，含两种属性。 </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logistic 回归]]></title>
    <link href="http://21stacks.top/14591708106259.html"/>
    <updated>2016-03-28T21:13:30+08:00</updated>
    <id>http://21stacks.top/14591708106259.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[线性回归]]></title>
    <link href="http://21stacks.top/14591708105958.html"/>
    <updated>2016-03-28T21:13:30+08:00</updated>
    <id>http://21stacks.top/14591708105958.html</id>
    <content type="html"><![CDATA[

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[去过东江湖]]></title>
    <link href="http://21stacks.top/14598276464760.html"/>
    <updated>2016-04-05T11:40:46+08:00</updated>
    <id>http://21stacks.top/14598276464760.html</id>
    <content type="html"><![CDATA[
<p><img src="http://7xrz9i.com1.z0.glb.clouddn.com/%E4%B8%9C%E6%B1%9F%E6%B9%96.jpg" alt=""/></p>

<span id="more"></span><!-- more -->

<blockquote>
<p>2015年9月12日 手机摄于东江湖.</p>
</blockquote>

<p>　　我总认为，近处的风景随时去看都可以，因此在长春待了四年，从未到过长白山。我还认为，太远的风景不值得舟车劳累长途跋涉，如今身在广州，长白山不去也罢。<br/>
　　生于湘南林邑，而这是我首次得以近览东江湖，若不是亲人邀请盛情难却，也不得成行。九月的天气已近秋，加之数日的连绵细雨，湖上竟刮起刺骨寒风。我们一群老少爷们在这风中冻得瑟瑟发抖，唯姨奶奶一人岿然屹立，迎风眺望，那意气风发的劲头着实让人惊叹。年过八旬的姨奶奶是奶奶的妹妹，年轻时在南车工作，退休后学起了国画、京剧，还独自一人游遍大江南北。这种气质，我羡慕，但我学不来。<br/>
　　等我不搬砖了，就找条小巷子，开个照相馆，就叫老曾照相馆。你看，人老去的样子千姿百态，也不知道会有几人光顾我的照相馆。管他呢，到那时候老子肯定很有钱。<br/>
　　<br/>
　　<br/>
　　<br/>
　　<br/>
　　</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[广美的气质]]></title>
    <link href="http://21stacks.top/14598440012972.html"/>
    <updated>2016-04-05T16:13:21+08:00</updated>
    <id>http://21stacks.top/14598440012972.html</id>
    <content type="html"><![CDATA[
<p><img src="http://7xrz9i.com1.z0.glb.clouddn.com/cold-guangmeiDSCF1485%E5%89%AF%E6%9C%AC.jpg" alt=""/></p>

<span id="more"></span><!-- more -->

<p><img src="http://7xrz9i.com1.z0.glb.clouddn.com/cold-guangmeiDSCF1490%E5%89%AF%E6%9C%AC.jpg" alt=""/></p>

<p><img src="http://7xrz9i.com1.z0.glb.clouddn.com/cold-guangmeiDSCF1480%E5%89%AF%E6%9C%AC.jpg" alt=""/></p>

<blockquote>
<p>2014年12月13日 摄于广州美术学院.</p>
</blockquote>

<p>　　十多年前我在一所县级中学里上初中，考试总是无缘无故地拿年级第一，那时候我梦想成为画家。后来去了市里读高中，我努力了好几把都没能考进年级前十，所以那时候我喜欢去网吧玩游戏。上大学了，班上同学信号与系统这门课都学得特好，但我还是觉得编程更有意思。<br/>
　　人都各有成长，但总会在某个时期，痴迷于那种和别人不一样的自我。<br/>
　　<br/>
　　<br/>
　　<br/>
　　</p>

]]></content>
  </entry>
  
</feed>
